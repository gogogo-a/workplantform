"""
æµ‹è¯• RAG å®Œæ•´æµç¨‹
åŒ…æ‹¬æ–‡æ¡£å¤„ç†ã€å‘é‡åŒ–ã€å­˜å‚¨ã€æ£€ç´¢
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from internal.rag.rag_service import rag_service
from internal.embedding.embedding_service import embedding_service
from internal.document.document_processor import document_processor


def test_embedding_service():
    """æµ‹è¯• Embedding æœåŠ¡"""
    print("=" * 80)
    print("æµ‹è¯• Embedding æœåŠ¡")
    print("=" * 80)
    
    try:
        # åŠ è½½æ¨¡å‹
        print("\nåŠ è½½ Embedding æ¨¡å‹...")
        embedding_service.load_model()
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        info = embedding_service.get_model_info()
        print(f"\næ¨¡å‹ä¿¡æ¯:")
        print(f"  åç§°: {info['model_name']}")
        print(f"  è·¯å¾„: {info['model_path']}")
        print(f"  ç»´åº¦: {info['dimension']}")
        print(f"  æœ€å¤§é•¿åº¦: {info['max_length']}")
        print(f"  è®¾å¤‡: {info['device']}")
        
        # æµ‹è¯•ç¼–ç 
        test_texts = [
            "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯",
            "æ·±åº¦å­¦ä¹ æ¨åŠ¨äº†AIçš„å¿«é€Ÿå‘å±•"
        ]
        
        print(f"\næµ‹è¯•æ–‡æœ¬ç¼–ç ...")
        embeddings = embedding_service.encode_documents(
            documents=test_texts,
            normalize=True,
            show_progress=False
        )
        
        print(f"âœ“ ç¼–ç å®Œæˆ")
        print(f"  æ–‡æœ¬æ•°: {len(test_texts)}")
        print(f"  å‘é‡å½¢çŠ¶: {embeddings.shape}")
        print(f"  å‘é‡ç»´åº¦: {embeddings.shape[1]}")
        
        # æµ‹è¯•æŸ¥è¯¢ç¼–ç 
        query = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
        print(f"\næµ‹è¯•æŸ¥è¯¢ç¼–ç : {query}")
        query_embedding = embedding_service.encode_query(query)
        print(f"âœ“ æŸ¥è¯¢å‘é‡å½¢çŠ¶: {query_embedding.shape}")
        
        print("\nâœ… Embedding æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ Embedding æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_document_processor():
    """æµ‹è¯•æ–‡æ¡£å¤„ç†"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ–‡æ¡£å¤„ç†")
    print("=" * 80)
    
    try:
        # åˆ›å»ºæµ‹è¯•æ–‡æœ¬æ–‡ä»¶
        test_file = os.path.join(project_root, "test_document.txt")
        with open(test_file, "w", encoding="utf-8") as f:
            f.write("""äººå·¥æ™ºèƒ½ç®€ä»‹

äººå·¥æ™ºèƒ½ï¼ˆArtificial Intelligenceï¼Œç®€ç§°AIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œ
å®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚

æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ã€‚é€šè¿‡è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ è§„å¾‹ï¼Œ
æœºå™¨å­¦ä¹ ä½¿å¾—è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å®Œæˆç‰¹å®šä»»åŠ¡ã€‚

æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œã€‚è¿‘å¹´æ¥ï¼Œ
æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ï¼Œ
æå¤§åœ°æ¨åŠ¨äº†äººå·¥æ™ºèƒ½çš„å‘å±•ã€‚

åº”ç”¨é¢†åŸŸåŒ…æ‹¬ï¼š
1. è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€äººè„¸è¯†åˆ«
2. è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆã€æƒ…æ„Ÿåˆ†æ
3. è¯­éŸ³è¯†åˆ«ï¼šè¯­éŸ³è½¬æ–‡å­—ã€è¯­éŸ³åŠ©æ‰‹
4. æ¨èç³»ç»Ÿï¼šä¸ªæ€§åŒ–æ¨èã€å†…å®¹ç­›é€‰

æœªæ¥å±•æœ›ï¼šäººå·¥æ™ºèƒ½å°†ç»§ç»­åœ¨å„ä¸ªé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œ
æ¨åŠ¨ç¤¾ä¼šè¿›æ­¥å’Œç§‘æŠ€å‘å±•ã€‚""")
        
        print(f"\nå¤„ç†æ–‡æ¡£: {test_file}")
        
        # å¤„ç†æ–‡æ¡£
        chunks = document_processor.process_document(test_file)
        
        print(f"\nâœ“ æ–‡æ¡£å¤„ç†å®Œæˆ")
        print(f"  æ–‡æœ¬å—æ•°: {len(chunks)}")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªå—
        print(f"\nå‰ 3 ä¸ªæ–‡æœ¬å—:")
        for i, chunk in enumerate(chunks[:3], 1):
            content = chunk["content"][:100] + "..." if len(chunk["content"]) > 100 else chunk["content"]
            print(f"\n  å— {i}:")
            print(f"    é•¿åº¦: {len(chunk['content'])} å­—ç¬¦")
            print(f"    å†…å®¹: {content}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = document_processor.get_stats(chunks)
        print(f"\næ–‡æ¡£ç»Ÿè®¡:")
        print(f"  æ€»å—æ•°: {stats['total_chunks']}")
        print(f"  å¹³å‡å¤§å°: {stats['avg_chunk_size']:.0f} å­—ç¬¦")
        print(f"  æœ€å°å—: {stats['min_chunk_size']} å­—ç¬¦")
        print(f"  æœ€å¤§å—: {stats['max_chunk_size']} å­—ç¬¦")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        os.remove(test_file)
        
        print("\nâœ… æ–‡æ¡£å¤„ç†æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ æ–‡æ¡£å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_rag_service():
    """æµ‹è¯•å®Œæ•´ RAG æœåŠ¡"""
    print("\n" + "=" * 80)
    print("æµ‹è¯• RAG æœåŠ¡")
    print("=" * 80)
    
    try:
        # åˆå§‹åŒ– RAG æœåŠ¡
        print("\nåˆå§‹åŒ– RAG æœåŠ¡...")
        rag_service.initialize()
        
        # åˆ›å»ºå¤šä¸ªæµ‹è¯•æ–‡æ¡£
        test_files = []
        
        # æ–‡æ¡£ 1: AI åŸºç¡€
        doc1 = os.path.join(project_root, "test_ai_basics.txt")
        with open(doc1, "w", encoding="utf-8") as f:
            f.write("""äººå·¥æ™ºèƒ½åŸºç¡€çŸ¥è¯†

äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„å®šä¹‰ï¼š
äººå·¥æ™ºèƒ½æ˜¯ç ”ç©¶ã€å¼€å‘ç”¨äºæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººçš„æ™ºèƒ½çš„ç†è®ºã€æ–¹æ³•ã€æŠ€æœ¯åŠåº”ç”¨ç³»ç»Ÿçš„ä¸€é—¨æ–°çš„æŠ€æœ¯ç§‘å­¦ã€‚

AI çš„ä¸‰ä¸ªå±‚æ¬¡ï¼š
1. å¼±äººå·¥æ™ºèƒ½ï¼ˆANIï¼‰ï¼šæ“…é•¿äºå•ä¸ªæ–¹é¢çš„äººå·¥æ™ºèƒ½ï¼Œå¦‚è¯­éŸ³è¯†åˆ«ã€å›¾åƒè¯†åˆ«
2. å¼ºäººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰ï¼šåœ¨å„æ–¹é¢éƒ½èƒ½å’Œäººç±»åª²ç¾çš„äººå·¥æ™ºèƒ½
3. è¶…äººå·¥æ™ºèƒ½ï¼ˆASIï¼‰ï¼šåœ¨æ‰€æœ‰é¢†åŸŸéƒ½æ¯”äººç±»å¼ºçš„äººå·¥æ™ºèƒ½

æ ¸å¿ƒæŠ€æœ¯åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰ã€‚""")
        test_files.append(doc1)
        
        # æ–‡æ¡£ 2: æœºå™¨å­¦ä¹ 
        doc2 = os.path.join(project_root, "test_ml.txt")
        with open(doc2, "w", encoding="utf-8") as f:
            f.write("""æœºå™¨å­¦ä¹ è¯¦è§£

æœºå™¨å­¦ä¹ çš„å®šä¹‰ï¼š
æœºå™¨å­¦ä¹ æ˜¯ä¸€é—¨å¤šé¢†åŸŸäº¤å‰å­¦ç§‘ï¼Œæ¶‰åŠæ¦‚ç‡è®ºã€ç»Ÿè®¡å­¦ã€é€¼è¿‘è®ºã€å‡¸åˆ†æã€ç®—æ³•å¤æ‚åº¦ç†è®ºç­‰å¤šé—¨å­¦ç§‘ã€‚

æœºå™¨å­¦ä¹ çš„åˆ†ç±»ï¼š
1. ç›‘ç£å­¦ä¹ ï¼šä»æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ é¢„æµ‹æ¨¡å‹
   - åˆ†ç±»é—®é¢˜ï¼šé¢„æµ‹ç¦»æ•£çš„ç±»åˆ«æ ‡ç­¾
   - å›å½’é—®é¢˜ï¼šé¢„æµ‹è¿ç»­çš„æ•°å€¼
   
2. æ— ç›‘ç£å­¦ä¹ ï¼šä»æ— æ ‡æ³¨æ•°æ®ä¸­å­¦ä¹ æ•°æ®çš„å†…åœ¨ç»“æ„
   - èšç±»ï¼šå°†ç›¸ä¼¼çš„æ•°æ®åˆ†ç»„
   - é™ç»´ï¼šå‡å°‘æ•°æ®çš„ç‰¹å¾æ•°é‡
   
3. å¼ºåŒ–å­¦ä¹ ï¼šé€šè¿‡ä¸ç¯å¢ƒäº¤äº’æ¥å­¦ä¹ æœ€ä¼˜ç­–ç•¥

å¸¸ç”¨ç®—æ³•åŒ…æ‹¬çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€å†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œç­‰ã€‚""")
        test_files.append(doc2)
        
        # æ–‡æ¡£ 3: FastAPI
        doc3 = os.path.join(project_root, "test_fastapi.txt")
        with open(doc3, "w", encoding="utf-8") as f:
            f.write("""FastAPI æ¡†æ¶ä»‹ç»

FastAPI æ˜¯ä»€ä¹ˆï¼š
FastAPI æ˜¯ä¸€ä¸ªç”¨äºæ„å»º API çš„ç°ä»£ã€å¿«é€Ÿï¼ˆé«˜æ€§èƒ½ï¼‰çš„ web æ¡†æ¶ï¼Œ
ä½¿ç”¨ Python 3.6+ å¹¶åŸºäºæ ‡å‡†çš„ Python ç±»å‹æç¤ºã€‚

ä¸»è¦ç‰¹ç‚¹ï¼š
1. å¿«é€Ÿï¼šå¯ä¸ NodeJS å’Œ Go æ¯”è‚©çš„æé«˜æ€§èƒ½
2. é«˜æ•ˆï¼šæé«˜å¼€å‘é€Ÿåº¦çº¦ 200% è‡³ 300%
3. æ›´å°‘çš„é”™è¯¯ï¼šå‡å°‘çº¦ 40% çš„äººä¸ºé”™è¯¯
4. æ™ºèƒ½ï¼šæä½³çš„ç¼–è¾‘å™¨æ”¯æŒï¼Œè‡ªåŠ¨è¡¥å…¨
5. ç®€å•ï¼šè®¾è®¡çš„æ˜“äºä½¿ç”¨å’Œå­¦ä¹ 
6. ç®€çŸ­ï¼šå‡å°‘ä»£ç é‡å¤
7. å¥å£®ï¼šç”Ÿäº§å¯ç”¨çº§åˆ«çš„ä»£ç ï¼Œè‡ªåŠ¨ç”Ÿæˆäº¤äº’å¼æ–‡æ¡£

æ ¸å¿ƒä¾èµ–ï¼š
- Starletteï¼šè´Ÿè´£ web éƒ¨åˆ†
- Pydanticï¼šè´Ÿè´£æ•°æ®éƒ¨åˆ†
- Uvicornï¼šASGI æœåŠ¡å™¨

é€‚ç”¨åœºæ™¯ï¼šæ„å»º RESTful APIã€å¾®æœåŠ¡ã€åç«¯æœåŠ¡ç­‰ã€‚""")
        test_files.append(doc3)
        
        print(f"\næ·»åŠ  {len(test_files)} ä¸ªæµ‹è¯•æ–‡æ¡£åˆ° RAG ç³»ç»Ÿ...")
        
        # æ·»åŠ æ–‡æ¡£
        result = rag_service.add_documents(test_files)
        
        print(f"\nâœ“ æ–‡æ¡£æ·»åŠ å®Œæˆ")
        print(f"  æ€»æ–‡æ¡£æ•°: {result['total_documents']}")
        print(f"  æ€»æ–‡æœ¬å—æ•°: {result['total_chunks']}")
        print(f"  æ€»å‘é‡æ•°: {result['total_vectors']}")
        print(f"  å‘é‡ç»´åº¦: {result['dimension']}")
        
        # æµ‹è¯•æœç´¢ - ä½¿ç”¨æ›´æœ‰å¯¹æ¯”æ€§çš„æŸ¥è¯¢
        test_queries = [
            {
                "query": "FastAPI æ¡†æ¶çš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                "expected": "test_fastapi.txt",
                "description": "ç²¾ç¡®æŸ¥è¯¢æµ‹è¯•ï¼ˆæœŸæœ›è¿”å› FastAPI æ–‡æ¡£ï¼‰"
            },
            {
                "query": "å¦‚ä½•è¿›è¡Œæœºå™¨å­¦ä¹ åˆ†ç±»ï¼Ÿ",
                "expected": "test_ml.txt", 
                "description": "è¯­ä¹‰æŸ¥è¯¢æµ‹è¯•ï¼ˆæœŸæœ›è¿”å›æœºå™¨å­¦ä¹ æ–‡æ¡£ï¼‰"
            }
        ]
        
        print(f"\n" + "=" * 80)
        print("æµ‹è¯•å‘é‡æ£€ç´¢ vs Reranker å¯¹æ¯”")
        print("=" * 80)
        
        for test_case in test_queries:
            query = test_case["query"]
            expected = test_case["expected"]
            description = test_case["description"]
            
            print(f"\n{'='*80}")
            print(f"ğŸ“ æµ‹è¯•ç”¨ä¾‹: {description}")
            print(f"ğŸ” æŸ¥è¯¢: {query}")
            print(f"ğŸ¯ æœŸæœ›æ¥æº: {expected}")
            print(f"{'='*80}")
            
            # 1. ä¸ä½¿ç”¨ Rerankerï¼ˆè·å–æ›´å¤šå€™é€‰ï¼‰
            print(f"\n{'â”€'*80}")
            print("ğŸ“Š é˜¶æ®µ 1: å‘é‡æ£€ç´¢ï¼ˆå¬å› Top 9 å€™é€‰æ–‡æ¡£ï¼‰")
            print(f"{'â”€'*80}")
            
            results_vector_only = rag_service.search(query, top_k=9, use_reranker=False)
            
            print(f"\nå‘é‡æ£€ç´¢ç»“æœ:")
            print(f"{'åºå·':<6} {'æ¥æº':<25} {'å‘é‡åˆ†æ•°':<12} {'å†…å®¹é¢„è§ˆ'}")
            print("-" * 80)
            
            for i, result in enumerate(results_vector_only, 1):
                filename = result['metadata'].get('filename', 'æœªçŸ¥')[:23]
                score = result['vector_score']
                content = result['text'][:40].replace('\n', ' ') + "..."
                
                # æ ‡è®°æ˜¯å¦æ˜¯æœŸæœ›æ–‡æ¡£
                marker = "âœ“" if expected in filename else " "
                print(f"{marker} #{i:<4} {filename:<25} {score:<12.4f} {content}")
            
            # 2. ä½¿ç”¨ Rerankerï¼ˆé‡æ’åº Top 3ï¼‰
            print(f"\n{'â”€'*80}")
            print("ğŸ”¥ é˜¶æ®µ 2: Reranker é‡æ’åºï¼ˆç²¾é€‰ Top 3ï¼‰")
            print(f"{'â”€'*80}")
            
            results_with_rerank = rag_service.search(query, top_k=3, use_reranker=True)
            
            print(f"\nReranker é‡æ’åºç»“æœ:")
            print(f"{'åºå·':<6} {'æ¥æº':<25} {'Rerankåˆ†æ•°':<14} {'å‘é‡åˆ†æ•°':<12} {'æ’åå˜åŒ–'}")
            print("-" * 90)
            
            for i, result in enumerate(results_with_rerank, 1):
                filename = result['metadata'].get('filename', 'æœªçŸ¥')[:23]
                rerank_score = result.get('rerank_score', 0)
                vector_score = result['vector_score']
                
                # æ‰¾åˆ°åŸå§‹æ’å
                original_rank = None
                for j, orig in enumerate(results_vector_only, 1):
                    if orig['id'] == result['id']:
                        original_rank = j
                        break
                
                rank_change = ""
                if original_rank:
                    if original_rank == i:
                        rank_change = "ä¿æŒ"
                    elif original_rank > i:
                        rank_change = f"â†‘ ä¸Šå‡ {original_rank - i} ä½"
                    else:
                        rank_change = f"â†“ ä¸‹é™ {i - original_rank} ä½"
                
                # æ ‡è®°æ˜¯å¦æ˜¯æœŸæœ›æ–‡æ¡£
                marker = "âœ“" if expected in filename else " "
                print(f"{marker} #{i:<4} {filename:<25} {rerank_score:<14.4f} {vector_score:<12.4f} {rank_change}")
            
            # 3. å¯¹æ¯”åˆ†æ
            print(f"\n{'â”€'*80}")
            print("ğŸ“ˆ æ•ˆæœå¯¹æ¯”åˆ†æ")
            print(f"{'â”€'*80}")
            
            # æ£€æŸ¥ Top 1 æ˜¯å¦æ­£ç¡®
            top1_vector = results_vector_only[0]['metadata'].get('filename', '')
            top1_rerank = results_with_rerank[0]['metadata'].get('filename', '')
            
            vector_correct = expected in top1_vector
            rerank_correct = expected in top1_rerank
            
            print(f"\nTop 1 ç»“æœ:")
            print(f"  å‘é‡æ£€ç´¢: {top1_vector:<30} {'âœ“ æ­£ç¡®' if vector_correct else 'âœ— é”™è¯¯'}")
            print(f"  Reranker:  {top1_rerank:<30} {'âœ“ æ­£ç¡®' if rerank_correct else 'âœ— é”™è¯¯'}")
            
            if rerank_correct and not vector_correct:
                print(f"\n  ğŸ’¡ Reranker æˆåŠŸçº æ­£äº†å‘é‡æ£€ç´¢çš„æ’åºï¼")
            elif rerank_correct and vector_correct:
                print(f"\n  âœ“ ä¸¤ç§æ–¹æ³•éƒ½è¿”å›äº†æ­£ç¡®ç»“æœ")
            
            # æ˜¾ç¤ºè¢«æ·˜æ±°çš„æ–‡æ¡£
            vector_ids = {r['id'] for r in results_vector_only[:3]}
            rerank_ids = {r['id'] for r in results_with_rerank}
            eliminated = vector_ids - rerank_ids
            
            if eliminated:
                print(f"\n  ğŸš« è¢« Reranker æ·˜æ±°çš„ä½è´¨é‡æ–‡æ¡£:")
                for result in results_vector_only[:3]:
                    if result['id'] in eliminated:
                        filename = result['metadata'].get('filename', 'æœªçŸ¥')
                        print(f"     - {filename} (å‘é‡åˆ†æ•°: {result['vector_score']:.4f})")
            
            print()
        
        # æµ‹è¯•è·å–ä¸Šä¸‹æ–‡
        print(f"\n" + "=" * 80)
        print("æµ‹è¯•ç”Ÿæˆ LLM ä¸Šä¸‹æ–‡")
        print("=" * 80)
        
        query = "ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åˆ†ç±»"
        print(f"\næŸ¥è¯¢: {query}")
        
        context = rag_service.get_context_for_query(query, top_k=3, max_context_length=1000)
        print(f"\nç”Ÿæˆçš„ä¸Šä¸‹æ–‡ ({len(context)} å­—ç¬¦):")
        print("-" * 80)
        print(context)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print(f"\n" + "=" * 80)
        print("é›†åˆç»Ÿè®¡ä¿¡æ¯")
        print("=" * 80)
        
        stats = rag_service.get_collection_stats()
        print(f"\né›†åˆåç§°: {stats.get('name', 'N/A')}")
        print(f"å®ä½“æ•°: {stats.get('num_entities', 0)}")
        print(f"Embedding æ¨¡å‹: {stats.get('embedding_model', 'N/A')}")
        print(f"å‘é‡ç»´åº¦: {stats.get('dimension', 0)}")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file in test_files:
            if os.path.exists(file):
                os.remove(file)
        
        print("\nâœ… RAG æœåŠ¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ RAG æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file in test_files:
            if os.path.exists(file):
                os.remove(file)
        
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯• RAG å®Œæ•´æµç¨‹\n")
    
    all_passed = True
    
    # æµ‹è¯• Embedding æœåŠ¡
    if not test_embedding_service():
        all_passed = False
        print("\nâš ï¸  Embedding æµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢åç»­æµ‹è¯•")
        return
    
    # æµ‹è¯•æ–‡æ¡£å¤„ç†
    if not test_document_processor():
        all_passed = False
    
    # æµ‹è¯• RAG æœåŠ¡
    if not test_rag_service():
        all_passed = False
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    if all_passed:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    print("=" * 80)
    
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("1. å‡†å¤‡æ–‡æ¡£ï¼ˆæ”¯æŒ .txt, .pdf, .docxï¼‰")
    print("2. ä½¿ç”¨ rag_service.add_documents([file_paths]) æ·»åŠ æ–‡æ¡£")
    print("3. ä½¿ç”¨ rag_service.search(query, use_reranker=True) æ£€ç´¢ç›¸å…³å†…å®¹")
    print("4. ä½¿ç”¨ rag_service.get_context_for_query(query) è·å– LLM ä¸Šä¸‹æ–‡")
    print("\nğŸ“Š æ¨èé…ç½®:")
    print("  - Embedding æ¨¡å‹: bge-large-zh-v1.5 (1024ç»´)")
    print("  - Reranker æ¨¡å‹: bge-reranker-v2-m3 (äºŒæ¬¡æ’åº)")
    print("  - Metric Type: COSINE")
    print("  - åˆ†å—å¤§å°: 500 å­—ç¬¦")
    print("  - åˆ†å—é‡å : 50 å­—ç¬¦")
    print("  - Top K: 3-5 ä¸ªç»“æœ")
    print("\nğŸ”¥ Reranker ä¼˜åŠ¿:")
    print("  - æé«˜æ£€ç´¢ç²¾åº¦ï¼Œæ·˜æ±°ä¸ç›¸å…³æ–‡æ¡£")
    print("  - å‡å°‘å™ªå£°ï¼Œæå‡ LLM ä¸Šä¸‹æ–‡è´¨é‡")
    print("  - åŸºäºè¯­ä¹‰æ·±åº¦ç†è§£ï¼Œæ¯”å‘é‡ç›¸ä¼¼åº¦æ›´å‡†ç¡®\n")


if __name__ == "__main__":
    main()

