"""
RAG æœåŠ¡ - LangChain ç‰ˆæœ¬
ä½¿ç”¨ LangChain çš„ VectorStoreRetriever å’Œ Milvus é›†æˆ

ç‰¹æ€§ï¼š
1. LangChain Milvus å‘é‡å­˜å‚¨
2. VectorStoreRetriever æ£€ç´¢å™¨
3. Reranker é‡æ’åºï¼ˆå¯é€‰ï¼‰
4. æ™ºèƒ½å»é‡
"""
from typing import List, Dict, Any, Optional
import logging
import time

from langchain_milvus import Milvus
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from langchain_core.embeddings import Embeddings

from internal.embedding.embedding_service import embedding_service
from internal.reranker.reranker_service import reranker_service
from pkg.model_list import BGE_LARGE_ZH_V1_5, BGE_RERANKER_V2_M3
from pkg.constants.constants import MILVUS_COLLECTION_NAME, MILVUS_HOST, MILVUS_PORT
from internal.monitor import performance_monitor, record_performance

logger = logging.getLogger(__name__)


class LangChainEmbeddingWrapper(Embeddings):
    """åŒ…è£…ç°æœ‰çš„ embedding_service ä¸º LangChain Embeddings"""
    
    def __init__(self, embedding_service):
        self.embedding_service = embedding_service
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """åµŒå…¥æ–‡æ¡£åˆ—è¡¨"""
        return self.embedding_service.encode_documents(texts)
    
    def embed_query(self, text: str) -> List[float]:
        """åµŒå…¥æŸ¥è¯¢"""
        return self.embedding_service.encode_query(text)


class RAGService:
    """RAG æœåŠ¡ç±» - LangChain ç‰ˆæœ¬"""
    
    def __init__(
        self,
        collection_name: Optional[str] = None,
        embedding_model: Optional[str] = None,
        reranker_model: Optional[str] = None,
        top_k: int = 5,
        use_reranker: bool = True
    ):
        """
        åˆå§‹åŒ– RAG æœåŠ¡ - LangChain ç‰ˆæœ¬
        
        Args:
            collection_name: Milvus é›†åˆåç§°
            embedding_model: Embedding æ¨¡å‹åç§°
            reranker_model: Reranker æ¨¡å‹åç§°
            top_k: æ£€ç´¢è¿”å›ç»“æœæ•°é‡
            use_reranker: æ˜¯å¦ä½¿ç”¨ Reranker
        """
        # é»˜è®¤é…ç½®
        if embedding_model is None:
            embedding_model = BGE_LARGE_ZH_V1_5.name
        if reranker_model is None:
            reranker_model = BGE_RERANKER_V2_M3.name
        if collection_name is None:
            collection_name = MILVUS_COLLECTION_NAME
        
        self.collection_name = collection_name
        self.embedding_model = embedding_model
        self.reranker_model = reranker_model
        self.top_k = top_k
        self.use_reranker = use_reranker
        
        # ğŸ”¥ åŒ…è£… embedding_service ä¸º LangChain Embeddings
        self.embeddings = LangChainEmbeddingWrapper(embedding_service)
        
        # ğŸ”¥ åˆå§‹åŒ– LangChain Milvus å‘é‡å­˜å‚¨
        # æ³¨æ„ï¼šä½¿ç”¨ç°æœ‰ collection çš„å­—æ®µå "embedding"ï¼Œè€Œä¸æ˜¯é»˜è®¤çš„ "vector"
        self.vector_store = Milvus(
            embedding_function=self.embeddings,
            collection_name=collection_name,
            connection_args={
                "host": MILVUS_HOST,
                "port": MILVUS_PORT
            },
            vector_field="embedding",  # ğŸ”¥ æŒ‡å®šå‘é‡å­—æ®µå
            text_field="text",          # ğŸ”¥ æŒ‡å®šæ–‡æœ¬å­—æ®µå
            auto_id=True                # ğŸ”¥ ä½¿ç”¨è‡ªåŠ¨ ID
        )
        
        # ğŸ”¥ åˆ›å»º Retriever
        self.retriever: BaseRetriever = self.vector_store.as_retriever(
            search_kwargs={"k": top_k * 2}  # å¤šæ£€ç´¢ä¸€äº›ï¼Œç”¨äºå»é‡å’Œ rerank
        )
        
        # Rerankerï¼ˆä¿æŒä¸å˜ï¼‰
        self.reranker = reranker_service if use_reranker else None
        
        logger.info(f"RAG æ£€ç´¢æœåŠ¡å·²åˆå§‹åŒ–ï¼ˆLangChain ç‰ˆæœ¬ï¼‰")
        logger.info(f"  é›†åˆåç§°: {collection_name}")
        logger.info(f"  Embedding æ¨¡å‹: {embedding_model}")
        logger.info(f"  Reranker æ¨¡å‹: {reranker_model if use_reranker else 'æœªå¯ç”¨'}")
    
    def _deduplicate_results(
        self,
        results: List[Dict[str, Any]],
        score_diff_threshold: float = 0.02,
        target_count: int = 5
    ) -> List[Dict[str, Any]]:
        """
        å»é‡æ£€ç´¢ç»“æœï¼šè¿‡æ»¤æ‰åˆ†æ•°æå…¶æ¥è¿‘çš„é‡å¤æ–‡æ¡£
        
        åˆ¤å®šæ ‡å‡†ï¼š
        - åˆ†æ•°å®Œå…¨ç›¸åŒ
        - æˆ–è€…åˆ†æ•°å·®å¼‚ <= 0.02ï¼ˆæ„å‘³ç€ç›¸ä¼¼åº¦ >= 98%ï¼‰
        
        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆå¿…é¡»åŒ…å«åˆ†æ•°å­—æ®µï¼‰
            score_diff_threshold: åˆ†æ•°å·®å¼‚é˜ˆå€¼ï¼Œé»˜è®¤0.02ï¼ˆ2%ï¼‰
            target_count: ç›®æ ‡è¿”å›æ•°é‡
            
        Returns:
            List[Dict]: å»é‡åçš„ç»“æœåˆ—è¡¨
        """
        if not results:
            return []
        
        # ç¡®å®šä½¿ç”¨å“ªä¸ªåˆ†æ•°å­—æ®µï¼ˆä¼˜å…ˆä½¿ç”¨ rerank_scoreï¼‰
        score_field = "rerank_score" if "rerank_score" in results[0] else "vector_score"
        
        # æŒ‰åˆ†æ•°é™åºæ’åºï¼ˆç¡®ä¿é«˜åˆ†åœ¨å‰ï¼‰
        sorted_results = sorted(results, key=lambda x: x.get(score_field, 0), reverse=True)
        
        deduplicated = []
        
        for current in sorted_results:
            current_score = current.get(score_field, 0)
            is_duplicate = False
            
            # æ£€æŸ¥æ˜¯å¦ä¸å·²é€‰ä¸­çš„æ–‡æ¡£é‡å¤
            for selected in deduplicated:
                selected_score = selected.get(score_field, 0)
                
                # è®¡ç®—åˆ†æ•°å·®å¼‚ï¼ˆç»å¯¹å€¼ï¼‰
                score_diff = abs(current_score - selected_score)
                
                # å¦‚æœåˆ†æ•°å·®å¼‚å°äºç­‰äºé˜ˆå€¼ï¼Œè®¤ä¸ºæ˜¯é‡å¤
                # ä¾‹å¦‚ï¼š0.95 å’Œ 0.94 å·®å¼‚ä¸º 0.01 < 0.02ï¼Œåˆ¤å®šä¸ºé‡å¤
                if score_diff <= score_diff_threshold:
                    is_duplicate = True
                    similarity_pct = (1 - score_diff) * 100
                    logger.debug(
                        f"å»é‡ï¼šæ–‡æ¡£ {current.get('id')} (åˆ†æ•°: {current_score:.4f}) "
                        f"ä¸ {selected.get('id')} (åˆ†æ•°: {selected_score:.4f}) "
                        f"å·®å¼‚: {score_diff:.4f} (ç›¸ä¼¼åº¦: {similarity_pct:.1f}%)ï¼Œåˆ¤å®šä¸ºé‡å¤"
                    )
                    break
            
            # å¦‚æœä¸æ˜¯é‡å¤ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
            if not is_duplicate:
                deduplicated.append(current)
                
                # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œåœæ­¢
                if len(deduplicated) >= target_count:
                    break
        
        logger.info(f"âœ“ å»é‡å®Œæˆï¼š{len(results)} -> {len(deduplicated)} ä¸ªæ–‡æ¡£")
        
        return deduplicated
    
    def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶ - LangChain ç‰ˆæœ¬ï¼ˆå·²åœ¨ __init__ ä¸­å®Œæˆï¼‰"""
        # ğŸ”¥ LangChain ç‰ˆæœ¬ä¸éœ€è¦æ‰‹åŠ¨åˆå§‹åŒ–ï¼Œåœ¨ __init__ ä¸­å·²ç»å®Œæˆ
        logger.info("RAG æœåŠ¡å·²åˆå§‹åŒ–ï¼ˆLangChain ç‰ˆæœ¬ï¼‰")
        return
    
    @performance_monitor('milvus_search', operation_name='å‘é‡æ£€ç´¢+Rerank', include_args=True, include_result=True)
    def search(
        self,
        query: str,
        top_k: Optional[int] = None,
        filter_metadata: Optional[Dict[str, Any]] = None,
        use_reranker: Optional[bool] = None,
        rerank_top_k: Optional[int] = None,
        rerank_score_threshold: float = -100.0,  # BGE reranker è¾“å‡º logitsï¼Œå¯ä»¥æ˜¯è´Ÿæ•°
        user_permission: int = 0  # ğŸ”¥ ç”¨æˆ·æƒé™ï¼ˆ0=æ™®é€šç”¨æˆ·ï¼Œ1=ç®¡ç†å‘˜ï¼‰
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸å…³æ–‡æ¡£ï¼ˆåŒ…å« Rerank å’Œå»é‡ï¼‰
        
        æµç¨‹ï¼š
        1. å‘é‡æ£€ç´¢
        2. æ ¹æ®ç”¨æˆ·æƒé™è¿‡æ»¤æ–‡æ¡£ï¼ˆæ™®é€šç”¨æˆ·åªèƒ½çœ‹permission=0çš„æ–‡æ¡£ï¼Œç®¡ç†å‘˜å¯ä»¥çœ‹æ‰€æœ‰æ–‡æ¡£ï¼‰
        3. Rerank é‡æ’åºï¼ˆå¯é€‰ï¼‰
        4. å»é‡ï¼šè¿‡æ»¤åˆ†æ•°å·®å¼‚ <= 0.02 (ç›¸ä¼¼åº¦ >= 98%) çš„é‡å¤æ–‡æ¡£
        5. è¿”å›æœ€å¤š top_k ä¸ªæœ€ç›¸å…³çš„ä¸é‡å¤æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: åˆå§‹å‘é‡æ£€ç´¢è¿”å›ç»“æœæ•°é‡ï¼ˆä¼šè¢« Reranker å¤„ç†ï¼‰
            filter_metadata: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            use_reranker: æ˜¯å¦ä½¿ç”¨ Rerankerï¼ˆNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤è®¾ç½®ï¼‰
            rerank_top_k: å»é‡åè¿”å›çš„ç»“æœæ•°é‡ï¼ˆé»˜è®¤5ä¸ªï¼ŒNone è¡¨ç¤ºä¸ top_k ç›¸åŒï¼‰
            rerank_score_threshold: Rerank åˆ†æ•°é˜ˆå€¼
            user_permission: ç”¨æˆ·æƒé™ï¼ˆ0=æ™®é€šç”¨æˆ·ï¼Œåªèƒ½æŸ¥è¯¢permission=0çš„æ–‡æ¡£ï¼›1=ç®¡ç†å‘˜ï¼Œå¯æŸ¥è¯¢æ‰€æœ‰æ–‡æ¡£ï¼‰
            
        Returns:
            List[Dict]: å»é‡åçš„æœç´¢ç»“æœåˆ—è¡¨ï¼ˆæœ€å¤š rerank_top_k ä¸ªä¸é‡å¤æ–‡æ¡£ï¼‰
        """
        try:
            if top_k is None:
                top_k = self.top_k
            else:
                # ç¡®ä¿ top_k æ˜¯æ•´æ•°ç±»å‹ï¼ˆå¯èƒ½ä»å·¥å…·è°ƒç”¨ä¼ å…¥å­—ç¬¦ä¸²ï¼‰
                top_k = int(top_k)
            
            if use_reranker is None:
                use_reranker = self.use_reranker
            
            if rerank_top_k is None:
                rerank_top_k = top_k
            else:
                rerank_top_k = int(rerank_top_k)
            
            logger.info(f"æœç´¢æŸ¥è¯¢: {query[:50]}...")
            
            # 1. ä½¿ç”¨ LangChain Retriever æ£€ç´¢ï¼ˆå†…éƒ¨ä¼šè‡ªåŠ¨è¿›è¡Œå‘é‡åŒ–ï¼‰
            embedding_start = time.time()
            
            # ğŸ”¥ ä½¿ç”¨ LangChain çš„ retriever.get_relevant_documents
            # æ³¨æ„ï¼šè¿™ä¼šè‡ªåŠ¨è°ƒç”¨ embeddings.embed_query è¿›è¡Œå‘é‡åŒ–
            docs: List[Document] = self.retriever.get_relevant_documents(query)
            
            embedding_duration = time.time() - embedding_start
            
            # è®°å½•æ£€ç´¢æ€§èƒ½
            record_performance(
                monitor_type='embedding',
                operation='å‘é‡æ£€ç´¢',
                duration=embedding_duration,
                query_length=len(query),
                text=query
            )
            
            # 2. æ ¼å¼åŒ– LangChain Document ä¸ºç»Ÿä¸€æ ¼å¼
            formatted_results = []
            for i, doc in enumerate(docs):
                result = {
                    "id": doc.metadata.get("id", f"doc_{i}"),
                    "text": doc.page_content,
                    "metadata": doc.metadata,
                    "vector_score": doc.metadata.get("score", 0.0),  # LangChain å¯èƒ½åœ¨ metadata ä¸­å­˜å‚¨åˆ†æ•°
                    "distance": doc.metadata.get("distance", 0.0)
                }
                
                # åº”ç”¨å…ƒæ•°æ®è¿‡æ»¤
                if filter_metadata:
                    match = all(
                        doc.metadata.get(k) == v
                        for k, v in filter_metadata.items()
                    )
                    if not match:
                        continue
                
                # ğŸ”¥ æƒé™è¿‡æ»¤ï¼šæ™®é€šç”¨æˆ·ï¼ˆuser_permission=0ï¼‰åªèƒ½çœ‹ permission=0 çš„æ–‡æ¡£
                # ğŸ“Œ å…¼å®¹æ€§å¤„ç†ï¼šæ—§æ–‡æ¡£æ²¡æœ‰ permission å­—æ®µï¼Œé»˜è®¤è§†ä¸º 0ï¼ˆæ™®é€šç”¨æˆ·å¯è§ï¼‰
                doc_permission = doc.metadata.get("permission", 0)  # é»˜è®¤ä¸º 0
                if user_permission == 0 and doc_permission == 1:
                    # æ™®é€šç”¨æˆ·ä¸èƒ½çœ‹ç®¡ç†å‘˜ä¸“å±æ–‡æ¡£
                    logger.debug(f"æƒé™è¿‡æ»¤ï¼šè·³è¿‡ç®¡ç†å‘˜æ–‡æ¡£ {result['id']}")
                    continue
                
                formatted_results.append(result)
            
            logger.info(f"âœ“ å‘é‡æ£€ç´¢å®Œæˆï¼Œè¿”å› {len(formatted_results)} æ¡å€™é€‰ï¼ˆå·²åº”ç”¨æƒé™è¿‡æ»¤ï¼Œuser_permission={user_permission}ï¼‰")
            
            # 4. Rerank æ­¥éª¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if use_reranker and self.reranker and formatted_results:
                logger.info(f"å¼€å§‹ Rerank...")
                
                reranked_results = self.reranker.rerank(
                    query=query,
                    documents=formatted_results,
                    top_k=rerank_top_k * 2,  # å…ˆè·å–æ›´å¤šç»“æœï¼Œå»é‡åå†æˆªå–
                    score_threshold=rerank_score_threshold
                )
                
                logger.info(f"âœ“ Rerank å®Œæˆï¼Œè¿”å› {len(reranked_results)} æ¡ç»“æœ")
                
                # 5. å»é‡ï¼šè¿‡æ»¤åˆ†æ•°å·®å¼‚ <= 0.02 çš„é‡å¤æ–‡æ¡£
                deduplicated_results = self._deduplicate_results(
                    results=reranked_results,
                    score_diff_threshold=0.02,
                    target_count=rerank_top_k
                )
                
                return deduplicated_results
            
            # 6. ä¸ä½¿ç”¨ Rerankerï¼Œç›´æ¥è¿”å›å‘é‡æ£€ç´¢ç»“æœï¼ˆä¹Ÿéœ€è¦å»é‡ï¼‰
            deduplicated_results = self._deduplicate_results(
                results=formatted_results,
                score_diff_threshold=0.02,
                target_count=rerank_top_k
            )
            
            return deduplicated_results
            
        except Exception as e:
            logger.error(f"âœ— æœç´¢å¤±è´¥: {e}")
            raise
    
    def get_context_for_query(
        self,
        query: str,
        top_k: Optional[int] = None,
        max_context_length: int = 2000,
        use_reranker: Optional[bool] = None,
        rerank_score_threshold: float = 0.0
    ) -> str:
        """
        è·å–æŸ¥è¯¢çš„ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆç”¨äº LLMï¼Œè‡ªåŠ¨åº”ç”¨ Rerankerï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            max_context_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            use_reranker: æ˜¯å¦ä½¿ç”¨ Reranker
            rerank_score_threshold: Rerank åˆ†æ•°é˜ˆå€¼
            
        Returns:
            str: æ‹¼æ¥çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        try:
            # æœç´¢ç›¸å…³æ–‡æ¡£ï¼ˆåŒ…å« Rerankï¼‰
            results = self.search(
                query,
                top_k=top_k,
                use_reranker=use_reranker,
                rerank_score_threshold=rerank_score_threshold
            )
            
            if not results:
                return ""
            
            # æ‹¼æ¥ä¸Šä¸‹æ–‡
            context_parts = []
            current_length = 0
            
            for i, result in enumerate(results, 1):
                text = result["text"]
                source = result["metadata"].get("filename", "æœªçŸ¥æ¥æº")
                
                # æ·»åŠ åˆ†æ•°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ rerank_scoreï¼‰
                score_info = ""
                if "rerank_score" in result:
                    score_info = f" (Rerankåˆ†æ•°: {result['rerank_score']:.4f})"
                
                # æ ¼å¼åŒ–å¼•ç”¨
                part = f"[æ–‡æ¡£{i} - {source}{score_info}]\n{text}\n"
                part_length = len(part)
                
                # æ£€æŸ¥é•¿åº¦é™åˆ¶
                if current_length + part_length > max_context_length:
                    break
                
                context_parts.append(part)
                current_length += part_length
            
            context = "\n".join(context_parts)
            
            logger.info(f"âœ“ ç”Ÿæˆä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(context)} å­—ç¬¦")
            
            return context
            
        except Exception as e:
            logger.error(f"âœ— è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return ""
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯ - LangChain ç‰ˆæœ¬"""
        try:
            # ğŸ”¥ LangChain ç‰ˆæœ¬ï¼šç›´æ¥ä»é…ç½®è¿”å›ä¿¡æ¯
            return {
                "collection_name": self.collection_name,
                "embedding_model": self.embedding_model,
                "reranker_model": self.reranker_model if self.use_reranker else None,
                "top_k": self.top_k
            }
        except Exception as e:
            logger.error(f"âœ— è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}


# ğŸ”¥ æ‡’åŠ è½½ï¼šå»¶è¿Ÿåˆ›å»ºå®ä¾‹ï¼Œé¿å…å¯¼å…¥æ—¶å°±åˆå§‹åŒ–æ¨¡å‹
_rag_service_instance = None

def get_rag_service():
    """è·å– RAG æœåŠ¡å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _rag_service_instance
    if _rag_service_instance is None:
        _rag_service_instance = RAGService(
            collection_name=None,  # ä½¿ç”¨å…¨å±€é…ç½® MILVUS_COLLECTION_NAME
            top_k=5,
            use_reranker=True
        )
    return _rag_service_instance

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™ rag_service å˜é‡ï¼ˆä½†ä½¿ç”¨å±æ€§è®¿é—®ï¼‰
class _RAGServiceProxy:
    """RAG æœåŠ¡ä»£ç†ï¼Œå®ç°æ‡’åŠ è½½"""
    def __getattr__(self, name):
        return getattr(get_rag_service(), name)

rag_service = _RAGServiceProxy()

