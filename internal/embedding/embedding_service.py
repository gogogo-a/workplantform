"""
Embedding æœåŠ¡
ä½¿ç”¨ bge-large-zh-v1.5 æ¨¡å‹è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
"""
# ğŸ”¥ å…³é”®ï¼šå¿…é¡»å…ˆå¯¼å…¥ constantsï¼Œè®¾ç½® HuggingFace ç¦»çº¿æ¨¡å¼
from pkg.constants.constants import RUNNING_MODE

from sentence_transformers import SentenceTransformer
from typing import List, Union, Optional
import numpy as np
import logging

from pkg.model_list import (
    get_embedding_model, 
    list_embedding_models, 
    ModelManager,
    BGE_LARGE_ZH_V1_5  # é»˜è®¤æ¨¡å‹é…ç½®
)

logger = logging.getLogger(__name__)


class EmbeddingService:
    """æ–‡æœ¬å‘é‡åŒ–æœåŠ¡ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    
    _instance: Optional['EmbeddingService'] = None
    _initialized: bool = False
    
    def __new__(cls, *args, **kwargs):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self, model_name: Optional[str] = None, device: Optional[str] = None):
        """
        åˆå§‹åŒ– Embedding æœåŠ¡
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨ BGE_LARGE_ZH_V1_5
            device: è®¾å¤‡ (cpu/cuda/mps)ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ RUNNING_MODE
        """
        # åªåˆå§‹åŒ–ä¸€æ¬¡
        if EmbeddingService._initialized:
            return
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if model_name is None:
            model_name = BGE_LARGE_ZH_V1_5.name
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè®¾å¤‡ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
        if device is None:
            device = RUNNING_MODE
            
        self.model_name = model_name
        self.device = device
        self.model = None
        self.model_config = None
        self.dimension = None
        self.max_length = None
        EmbeddingService._initialized = True
        logger.info(f"Embedding æœåŠ¡å·²åˆå§‹åŒ–: {model_name}, è®¾å¤‡: {device}")
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if self.model is not None:
            logger.info(f"æ¨¡å‹å·²åŠ è½½: {self.model_name}")
            return
        
        try:
            # ä»ç»Ÿä¸€é…ç½®ä¸­è·å–æ¨¡å‹é…ç½®
            self.model_config = get_embedding_model(self.model_name)
            
            logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_config.model_path}")
            logger.info(f"æè¿°: {self.model_config.description}")
            logger.info(f"ç»´åº¦: {self.model_config.dimension}")
            logger.info(f"æœ€å¤§é•¿åº¦: {self.model_config.max_length}")
            
            # ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨åŠ è½½æ¨¡å‹
            self.model = ModelManager.select_embedding_model(self.model_name, self.device)
            self.dimension = self.model_config.dimension
            self.max_length = self.model_config.max_length
            
            logger.info(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_name}")
            logger.info(f"âœ“ ä½¿ç”¨è®¾å¤‡: {self.device}")
            
        except Exception as e:
            logger.error(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise Exception(f"åŠ è½½ Embedding æ¨¡å‹å¤±è´¥: {e}")
    
    def encode(
        self,
        texts: Union[str, List[str]],
        batch_size: int = 32,
        normalize: bool = True,
        show_progress: bool = False
    ) -> np.ndarray:
        """
        æ–‡æœ¬å‘é‡åŒ–
        
        Args:
            texts: å•ä¸ªæ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            normalize: æ˜¯å¦å½’ä¸€åŒ–ï¼ˆä½¿ç”¨ COSINE æ—¶å»ºè®® Trueï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
            
        Returns:
            np.ndarray: å‘é‡æ•°ç»„
        """
        # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if self.model is None:
            self.load_model()
        
        try:
            # è½¬æ¢ä¸ºåˆ—è¡¨
            if isinstance(texts, str):
                texts = [texts]
                single_text = True
            else:
                single_text = False
            
            # å¯¹äº BGE æ¨¡å‹ï¼ŒæŸ¥è¯¢æ–‡æœ¬éœ€è¦æ·»åŠ å‰ç¼€
            if "bge" in self.model_name.lower():
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å‰ç¼€
                processed_texts = []
                for text in texts:
                    if not text.startswith("ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š"):
                        processed_texts.append(f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š{text}")
                    else:
                        processed_texts.append(text)
                texts = processed_texts
            
            # ç¼–ç 
            embeddings = self.model.encode(
                texts,
                batch_size=batch_size,
                normalize_embeddings=normalize,
                show_progress_bar=show_progress,
                convert_to_numpy=True
            )
            
            # å¦‚æœæ˜¯å•ä¸ªæ–‡æœ¬ï¼Œè¿”å›ä¸€ç»´æ•°ç»„
            if single_text:
                return embeddings[0]
            
            return embeddings
            
        except Exception as e:
            logger.error(f"âœ— æ–‡æœ¬ç¼–ç å¤±è´¥: {e}")
            raise
    
    def encode_query(
        self,
        query: str,
        normalize: bool = True
    ) -> np.ndarray:
        """
        æŸ¥è¯¢æ–‡æœ¬å‘é‡åŒ–ï¼ˆé’ˆå¯¹æœç´¢ä¼˜åŒ–ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            normalize: æ˜¯å¦å½’ä¸€åŒ–
            
        Returns:
            np.ndarray: æŸ¥è¯¢å‘é‡
        """
        if self.model is None:
            self.load_model()
        
        try:
            # BGE æ¨¡å‹çš„æŸ¥è¯¢éœ€è¦æ·»åŠ ç‰¹æ®Šå‰ç¼€
            if "bge" in self.model_name.lower():
                query = f"ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š{query}"
            
            embedding = self.model.encode(
                query,
                normalize_embeddings=normalize,
                convert_to_numpy=True
            )
            
            return embedding
            
        except Exception as e:
            logger.error(f"âœ— æŸ¥è¯¢ç¼–ç å¤±è´¥: {e}")
            raise
    
    def encode_documents(
        self,
        documents: List[str],
        batch_size: int = 32,
        normalize: bool = True,
        show_progress: bool = True
    ) -> np.ndarray:
        """
        æ–‡æ¡£å‘é‡åŒ–ï¼ˆä¸æ·»åŠ æŸ¥è¯¢å‰ç¼€ï¼‰
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            batch_size: æ‰¹å¤„ç†å¤§å°
            normalize: æ˜¯å¦å½’ä¸€åŒ–
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            np.ndarray: æ–‡æ¡£å‘é‡æ•°ç»„
        """
        if self.model is None:
            self.load_model()
        
        try:
            # æ–‡æ¡£ä¸éœ€è¦æ·»åŠ å‰ç¼€ï¼Œç›´æ¥ç¼–ç 
            embeddings = self.model.encode(
                documents,
                batch_size=batch_size,
                normalize_embeddings=normalize,
                show_progress_bar=show_progress,
                convert_to_numpy=True
            )
            
            return embeddings
            
        except Exception as e:
            logger.error(f"âœ— æ–‡æ¡£ç¼–ç å¤±è´¥: {e}")
            raise
    
    def get_model_info(self) -> dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        try:
            if self.model_config is None:
                self.model_config = get_embedding_model(self.model_name)
            
            return {
                "model_name": self.model_name,
                "model_path": self.model_config.model_path,
                "dimension": self.dimension or self.model_config.dimension,
                "max_length": self.max_length or self.model_config.max_length,
                "description": self.model_config.description,
                "device": self.device,
                "loaded": self.model is not None
            }
        except Exception as e:
            return {"error": str(e)}
    
    @classmethod
    def list_available_models(cls) -> List[dict]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        return [config.to_dict() for config in list_embedding_models()]


# åˆ›å»ºå…¨å±€å•ä¾‹å®ä¾‹ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ BGE_LARGE_ZH_V1_5ï¼‰
embedding_service = EmbeddingService()

