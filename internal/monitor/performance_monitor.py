"""
æ€§èƒ½ç›‘æ§æ¨¡å—

æä¾›è£…é¥°å™¨å’Œå·¥å…·æ¥ç›‘æ§å…³é”®æ“ä½œçš„æ‰§è¡Œæ—¶é—´
ç›‘æ§æ•°æ®æŒ‰å¤©ã€æŒ‰ç±»å‹ä¿å­˜åˆ° json_monitor/ ç›®å½•

ç›‘æ§ç±»å‹ï¼š
- embedding: Embedding å‘é‡åŒ–æ“ä½œ
- milvus_search: Milvus å‘é‡æœç´¢
- llm_think: LLM æ€è€ƒè¿‡ç¨‹
- llm_action: LLM åŠ¨ä½œæ‰§è¡Œ
- llm_answer: LLM ç­”æ¡ˆç”Ÿæˆ
- llm_total: LLM å®Œæ•´å¯¹è¯
- agent_total: Agent å®Œæ•´æ¨ç†
"""

import time
import json
import asyncio
from pathlib import Path
from datetime import datetime
from functools import wraps
from typing import Any, Callable, Dict, Optional
from log import logger


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ç®¡ç†å™¨"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        # ç›‘æ§æ•°æ®ä¿å­˜ç›®å½•
        project_root = Path(__file__).parent.parent.parent
        self.monitor_dir = project_root / "json_monitor"
        self.monitor_dir.mkdir(exist_ok=True)
        
        self._initialized = True
        logger.info(f"æ€§èƒ½ç›‘æ§ç³»ç»Ÿå·²åˆå§‹åŒ–ï¼Œç›‘æ§ç›®å½•: {self.monitor_dir}")
    
    def _get_file_path(self, monitor_type: str) -> Path:
        """
        è·å–ç›‘æ§æ•°æ®æ–‡ä»¶è·¯å¾„
        
        æ ¼å¼: json_monitor/YY_MM_DD_monitor/{type}.json
        ä¾‹å¦‚: json_monitor/25_10_26_monitor/embedding.json
        
        Args:
            monitor_type: ç›‘æ§ç±»å‹ï¼ˆembedding, milvus_search, llm_think ç­‰ï¼‰
        
        Returns:
            Path: æ–‡ä»¶è·¯å¾„
        """
        # ä½¿ç”¨å’Œ json_log ç›¸åŒçš„æ—¥æœŸæ ¼å¼ï¼šYY_MM_DD_monitor
        today_dir = datetime.now().strftime("%y_%m_%d_monitor")
        monitor_subdir = self.monitor_dir / today_dir
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        monitor_subdir.mkdir(exist_ok=True)
        
        # æ–‡ä»¶åï¼š{type}.json
        filename = f"{monitor_type}.json"
        return monitor_subdir / filename
    
    def record(
        self, 
        monitor_type: str,
        operation: str,
        duration: float,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """
        è®°å½•æ€§èƒ½æ•°æ®åˆ° JSON æ–‡ä»¶
        
        Args:
            monitor_type: ç›‘æ§ç±»å‹
            operation: æ“ä½œåç§°
            duration: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
            metadata: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå¦‚è¾“å…¥å¤§å°ã€è¾“å‡ºå¤§å°ç­‰ï¼‰
                     - token_count: token æ•°é‡ï¼ˆç”¨äºè®¡ç®— tokens/sï¼‰
        """
        try:
            file_path = self._get_file_path(monitor_type)
            
            # æ„å»ºç›‘æ§è®°å½•
            record = {
                "timestamp": datetime.now().isoformat(),
                "operation": operation,
                "duration_ms": round(duration * 1000, 2),  # è½¬æ¢ä¸ºæ¯«ç§’
                "duration_s": round(duration, 4),  # ä¿ç•™ç§’
            }
            
            # æ·»åŠ å…ƒæ•°æ®
            if metadata:
                # ğŸ”¥ å¦‚æœmetadataä¸­æœ‰ 'text' å­—æ®µï¼Œè‡ªåŠ¨è®¡ç®— token_count
                if "text" in metadata and "token_count" not in metadata:
                    text = metadata["text"]
                    token_count = _estimate_token_count(text)
                    if token_count > 0:
                        metadata["token_count"] = token_count
                
                record["metadata"] = metadata
                
                # ğŸ”¥ å¦‚æœæœ‰ token_countï¼Œè‡ªåŠ¨è®¡ç®— token å¤„ç†é€Ÿåº¦
                if "token_count" in metadata and metadata["token_count"] > 0:
                    token_count = metadata["token_count"]
                    
                    # è®¡ç®— tokens/s
                    if duration > 0:
                        tokens_per_second = round(token_count / duration, 2)
                        record["tokens_per_second"] = tokens_per_second
                        
                        # è®¡ç®—æ¯ 10000 tokens çš„å¤„ç†æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                        ms_per_10k_tokens = round((duration * 1000 * 10000) / token_count, 2)
                        record["ms_per_10k_tokens"] = ms_per_10k_tokens
            
            # è¿½åŠ å†™å…¥æ–‡ä»¶ï¼ˆNDJSON æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ª JSONï¼‰
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(record, ensure_ascii=False) + '\n')
            
            # è®°å½•åˆ°æ—¥å¿—ï¼ˆç®€åŒ–ç‰ˆï¼ŒåŒ…å« token é€Ÿåº¦ä¿¡æ¯ï¼‰
            log_msg = f"â±ï¸  [{monitor_type}] {operation}: {record['duration_ms']}ms"
            if "tokens_per_second" in record:
                log_msg += f", {record['tokens_per_second']} tokens/s, {record['ms_per_10k_tokens']}ms/10k tokens"
            
            logger.debug(log_msg, **metadata if metadata else {})
        
        except Exception as e:
            logger.error(f"æ€§èƒ½ç›‘æ§è®°å½•å¤±è´¥: {e}", exc_info=True)


# å…¨å±€å•ä¾‹
_monitor = PerformanceMonitor()


def _estimate_token_count(text: Any) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    
    ç®€åŒ–ç®—æ³•ï¼š
    - ä¸­æ–‡ï¼š1 å­—ç¬¦ â‰ˆ 1 token
    - è‹±æ–‡ï¼š4 å­—ç¬¦ â‰ˆ 1 token
    - æ ‡ç‚¹ç¬¦å·ï¼š1 ä¸ª â‰ˆ 1 token
    
    Args:
        text: æ–‡æœ¬ï¼ˆå­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
    
    Returns:
        int: ä¼°ç®—çš„ token æ•°é‡
    """
    try:
        # å¤„ç†åˆ—è¡¨
        if isinstance(text, (list, tuple)):
            return sum(_estimate_token_count(t) for t in text)
        
        # å¤„ç†å­—ç¬¦ä¸²
        if isinstance(text, str):
            # ç®€åŒ–ä¼°ç®—ï¼šæ€»å­—ç¬¦æ•° * 0.8ï¼ˆè€ƒè™‘ä¸­è‹±æ–‡æ··åˆï¼‰
            return int(len(text) * 0.8)
        
        return 0
    except:
        return 0


def performance_monitor(
    monitor_type: str,
    operation_name: Optional[str] = None,
    include_args: bool = False,
    include_result: bool = False
):
    """
    åŒæ­¥å‡½æ•°æ€§èƒ½ç›‘æ§è£…é¥°å™¨
    
    Args:
        monitor_type: ç›‘æ§ç±»å‹ï¼ˆembedding, milvus_search, llm_think ç­‰ï¼‰
        operation_name: æ“ä½œåç§°ï¼ˆé»˜è®¤ä½¿ç”¨å‡½æ•°åï¼‰
        include_args: æ˜¯å¦åœ¨å…ƒæ•°æ®ä¸­åŒ…å«å‡½æ•°å‚æ•°
        include_result: æ˜¯å¦åœ¨å…ƒæ•°æ®ä¸­åŒ…å«è¿”å›å€¼ä¿¡æ¯
    
    ç”¨æ³•:
        @performance_monitor('embedding', operation_name='æ–‡æ¡£å‘é‡åŒ–')
        def encode_documents(documents):
            ...
    """
    def decorator(func: Callable) -> Callable:
        op_name = operation_name or f"{func.__module__}.{func.__name__}"
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            metadata = {}
            
            # è®°å½•å‚æ•°ä¿¡æ¯
            if include_args:
                try:
                    # åªè®°å½•ç®€å•ç±»å‹å’Œæ•°é‡
                    if args:
                        metadata['args_count'] = len(args)
                        # å¦‚æœç¬¬ä¸€ä¸ªå‚æ•°æ˜¯åˆ—è¡¨ï¼Œè®°å½•é•¿åº¦
                        if isinstance(args[0], (list, tuple)):
                            metadata['input_count'] = len(args[0])
                    if kwargs:
                        metadata['kwargs_keys'] = list(kwargs.keys())
                except:
                    pass
            
            # ğŸ”¥ å¯¹äº embedding ç±»å‹ï¼Œè‡ªåŠ¨è®¡ç®— token æ•°é‡
            if monitor_type == 'embedding':
                try:
                    # å°è¯•ä»å‚æ•°ä¸­æå–æ–‡æœ¬
                    texts = None
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç±»æ–¹æ³•ï¼ˆç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ selfï¼‰
                    start_index = 1 if args and hasattr(args[0], '__dict__') else 0
                    
                    # ä»ä½ç½®å‚æ•°æå–ï¼ˆè·³è¿‡ selfï¼‰
                    if args and len(args) > start_index:
                        texts = args[start_index]
                    # ä»å…³é”®å­—å‚æ•°æå–
                    elif 'texts' in kwargs:
                        texts = kwargs['texts']
                    elif 'query' in kwargs:
                        texts = kwargs['query']
                    elif 'documents' in kwargs:
                        texts = kwargs['documents']
                    
                    if texts:
                        token_count = _estimate_token_count(texts)
                        if token_count > 0:
                            metadata['token_count'] = token_count
                except:
                    pass
            
            try:
                result = func(*args, **kwargs)
                
                # è®°å½•è¿”å›å€¼ä¿¡æ¯
                if include_result and result is not None:
                    try:
                        if isinstance(result, (list, tuple)):
                            metadata['output_count'] = len(result)
                        elif hasattr(result, '__len__'):
                            metadata['output_size'] = len(result)
                    except:
                        pass
                
                duration = time.time() - start_time
                metadata['status'] = 'success'
                _monitor.record(monitor_type, op_name, duration, metadata)
                
                return result
            
            except Exception as e:
                duration = time.time() - start_time
                metadata['status'] = 'error'
                metadata['error_type'] = type(e).__name__
                metadata['error_message'] = str(e)
                _monitor.record(monitor_type, op_name, duration, metadata)
                raise
        
        return wrapper
    return decorator


def async_performance_monitor(
    monitor_type: str,
    operation_name: Optional[str] = None,
    include_args: bool = False,
    include_result: bool = False
):
    """
    å¼‚æ­¥å‡½æ•°æ€§èƒ½ç›‘æ§è£…é¥°å™¨
    
    Args:
        monitor_type: ç›‘æ§ç±»å‹
        operation_name: æ“ä½œåç§°ï¼ˆé»˜è®¤ä½¿ç”¨å‡½æ•°åï¼‰
        include_args: æ˜¯å¦åœ¨å…ƒæ•°æ®ä¸­åŒ…å«å‡½æ•°å‚æ•°
        include_result: æ˜¯å¦åœ¨å…ƒæ•°æ®ä¸­åŒ…å«è¿”å›å€¼ä¿¡æ¯
    
    ç”¨æ³•:
        @async_performance_monitor('milvus_search', operation_name='å‘é‡æ£€ç´¢')
        async def search_vectors(query_vector, top_k):
            ...
    """
    def decorator(func: Callable) -> Callable:
        op_name = operation_name or f"{func.__module__}.{func.__name__}"
        
        @wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            metadata = {}
            
            # è®°å½•å‚æ•°ä¿¡æ¯
            if include_args:
                try:
                    if args:
                        metadata['args_count'] = len(args)
                        if isinstance(args[0], (list, tuple)):
                            metadata['input_count'] = len(args[0])
                    if kwargs:
                        metadata['kwargs_keys'] = list(kwargs.keys())
                except:
                    pass
            
            # ğŸ”¥ å¯¹äº embedding ç±»å‹ï¼Œè‡ªåŠ¨è®¡ç®— token æ•°é‡
            if monitor_type == 'embedding':
                try:
                    # å°è¯•ä»å‚æ•°ä¸­æå–æ–‡æœ¬
                    texts = None
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç±»æ–¹æ³•ï¼ˆç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ selfï¼‰
                    start_index = 1 if args and hasattr(args[0], '__dict__') else 0
                    
                    # ä»ä½ç½®å‚æ•°æå–ï¼ˆè·³è¿‡ selfï¼‰
                    if args and len(args) > start_index:
                        texts = args[start_index]
                    # ä»å…³é”®å­—å‚æ•°æå–
                    elif 'texts' in kwargs:
                        texts = kwargs['texts']
                    elif 'query' in kwargs:
                        texts = kwargs['query']
                    elif 'documents' in kwargs:
                        texts = kwargs['documents']
                    
                    if texts:
                        token_count = _estimate_token_count(texts)
                        if token_count > 0:
                            metadata['token_count'] = token_count
                except:
                    pass
            
            try:
                result = await func(*args, **kwargs)
                
                # è®°å½•è¿”å›å€¼ä¿¡æ¯
                if include_result and result is not None:
                    try:
                        if isinstance(result, (list, tuple)):
                            metadata['output_count'] = len(result)
                        elif hasattr(result, '__len__'):
                            metadata['output_size'] = len(result)
                    except:
                        pass
                
                duration = time.time() - start_time
                metadata['status'] = 'success'
                _monitor.record(monitor_type, op_name, duration, metadata)
                
                return result
            
            except Exception as e:
                duration = time.time() - start_time
                metadata['status'] = 'error'
                metadata['error_type'] = type(e).__name__
                metadata['error_message'] = str(e)
                _monitor.record(monitor_type, op_name, duration, metadata)
                raise
        
        return wrapper
    return decorator


# ==================== ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ˆç”¨äºæ‰‹åŠ¨è®¡æ—¶ï¼‰====================

class PerformanceTimer:
    """
    æ€§èƒ½è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    ç”¨æ³•:
        with PerformanceTimer('llm_think', 'æ¨ç†æ­¥éª¤1'):
            # æ‰§è¡Œè€—æ—¶æ“ä½œ
            result = llm.generate(prompt)
    """
    
    def __init__(self, monitor_type: str, operation: str, metadata: Optional[Dict] = None):
        self.monitor_type = monitor_type
        self.operation = operation
        self.metadata = metadata or {}
        self.start_time = None
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time
        
        if exc_type is not None:
            self.metadata['status'] = 'error'
            self.metadata['error_type'] = exc_type.__name__
            self.metadata['error_message'] = str(exc_val)
        else:
            self.metadata['status'] = 'success'
        
        _monitor.record(self.monitor_type, self.operation, duration, self.metadata)
        
        # ä¸æŠ‘åˆ¶å¼‚å¸¸
        return False


class AsyncPerformanceTimer:
    """
    å¼‚æ­¥æ€§èƒ½è®¡æ—¶å™¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    ç”¨æ³•:
        async with AsyncPerformanceTimer('milvus_search', 'æ£€ç´¢æ–‡æ¡£'):
            results = await milvus.search(...)
    """
    
    def __init__(self, monitor_type: str, operation: str, metadata: Optional[Dict] = None):
        self.monitor_type = monitor_type
        self.operation = operation
        self.metadata = metadata or {}
        self.start_time = None
    
    async def __aenter__(self):
        self.start_time = time.time()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time
        
        if exc_type is not None:
            self.metadata['status'] = 'error'
            self.metadata['error_type'] = exc_type.__name__
            self.metadata['error_message'] = str(exc_val)
        else:
            self.metadata['status'] = 'success'
        
        _monitor.record(self.monitor_type, self.operation, duration, self.metadata)
        
        return False


# ==================== ä¾¿æ·å‡½æ•° ====================

def record_performance(
    monitor_type: str,
    operation: str,
    duration: float,
    **metadata
):
    """
    ç›´æ¥è®°å½•æ€§èƒ½æ•°æ®ï¼ˆä¸ä½¿ç”¨è£…é¥°å™¨ï¼‰
    
    ç”¨æ³•:
        start = time.time()
        result = do_something()
        record_performance('embedding', 'å‘é‡åŒ–', time.time() - start, count=100)
    """
    _monitor.record(monitor_type, operation, duration, metadata)
