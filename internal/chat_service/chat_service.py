"""
èŠå¤©æœåŠ¡ï¼ˆä¸Šå±‚å°è£…ï¼‰
è´Ÿè´£ï¼š
1. Session å’Œ User ç®¡ç†
2. è°ƒç”¨åº•å±‚ LLMService
3. å°è£… Agent äº¤äº’ï¼ˆç»Ÿä¸€å…¥å£ï¼‰

Note: å†å²è®°å½•æŒä¹…åŒ–ï¼ˆRedis/MongoDBï¼‰åº”åœ¨ API Server å±‚å®ç°
"""
from typing import Optional, List, Dict, Any, Callable
from internal.llm.llm_service import LLMService
from pkg.constants.constants import MAX_TOKEN


class ChatService:
    """
    èŠå¤©æœåŠ¡ - ä¸Šå±‚å°è£…
    ç®¡ç†ä¼šè¯ã€ç”¨æˆ·ã€å°è£… LLM å’Œ Agent è°ƒç”¨
    """
    
    def __init__(
        self,
        session_id: str,
        user_id: str,
        model_name: Optional[str] = None,
        model_type: Optional[str] = None,
        system_prompt: Optional[str] = None,
        tools: Optional[List[Callable]] = None,
        auto_summary: bool = True,
        max_history_count: int = 10,
        max_history_tokens: int = MAX_TOKEN
    ):
        """
        åˆå§‹åŒ–èŠå¤©æœåŠ¡
        
        Args:
            session_id: ä¼šè¯IDï¼ˆå¿…å¡«ï¼‰
            user_id: ç”¨æˆ·IDï¼ˆå¿…å¡«ï¼‰
            model_name: æ¨¡å‹åç§°
            model_type: æ¨¡å‹ç±»å‹ (local/cloud)
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            tools: å·¥å…·åˆ—è¡¨
            auto_summary: æ˜¯å¦è‡ªåŠ¨æ€»ç»“
            max_history_count: æœ€å¤§å†å²è®°å½•æ¡æ•°
            max_history_tokens: æœ€å¤§å†å²è®°å½•tokenæ•°
        """
        self.session_id = session_id
        self.user_id = user_id
        
        # åˆå§‹åŒ–åº•å±‚ LLM æœåŠ¡ï¼ˆçº¯ç²¹çš„ LLM è°ƒç”¨ï¼‰
        self.llm_service = LLMService(
            model_name=model_name,
            model_type=model_type,
            system_prompt=system_prompt,
            tools=tools,
            auto_summary=auto_summary,
            max_history_count=max_history_count,
            max_history_tokens=max_history_tokens
        )
        
        print(f"âœ“ ChatService å·²åˆå§‹åŒ–")
        print(f"  Session: {self.session_id}")
        print(f"  User: {self.user_id}")
    
    def _chat_with_agent(
        self,
        question: str,
        agent_tools: Dict[str, Callable],
        save_only_answer: bool = True,
        max_iterations: int = 5,
        verbose: bool = True
    ) -> str:
        """
        ä½¿ç”¨ Agent è¿›è¡Œå¯¹è¯ï¼ˆReAct æ¡†æ¶ï¼‰- å†…éƒ¨æ–¹æ³•
        
        é€šè¿‡ chat(use_agent=True) è°ƒç”¨ï¼Œä¸å»ºè®®ç›´æ¥ä½¿ç”¨
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            agent_tools: Agent å¯ç”¨çš„å·¥å…·å­—å…¸
            save_only_answer: æ˜¯å¦åªä¿å­˜æœ€ç»ˆç­”æ¡ˆ
            max_iterations: Agent æœ€å¤§æ¨ç†è½®æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹
            
        Returns:
            æœ€ç»ˆç­”æ¡ˆ
        """
        
        # å¯¼å…¥ ReActAgentï¼ˆå»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–ï¼‰
        from internal.agent.react_agent import ReActAgent
        
        # ğŸ”¥ å…³é”®ï¼šè®°å½•å†å²é•¿åº¦ï¼Œç”¨äºåç»­æ§åˆ¶
        history_start_length = len(self.llm_service.chat_history)
        
        # åˆ›å»º Agentï¼ˆAgent ä¸å†å¤„ç†å†å²è®°å½•ï¼Œç”± ChatService ç»Ÿä¸€ç®¡ç†ï¼‰
        agent = ReActAgent(
            llm_service=self.llm_service,
            tools=agent_tools,
            max_iterations=max_iterations,
            verbose=verbose
        )
        
        # è¿è¡Œ Agentï¼ˆä¼šè‡ªåŠ¨è°ƒç”¨ llm_serviceï¼Œäº§ç”Ÿä¸­é—´å†å²ï¼‰
        answer = agent.run(question, stream=verbose)
        
        # ğŸ”¥ ChatService ç»Ÿä¸€å¤„ç†å†å²è®°å½•
        if save_only_answer:
            # âœ… åªä¿å­˜é—®ç­”ï¼ˆæ¸…é™¤æ‰€æœ‰ä¸­é—´è¿‡ç¨‹ï¼‰
            self.llm_service.chat_history = self.llm_service.chat_history[:history_start_length]
            
            # æ·»åŠ ç®€æ´çš„é—®ç­”å¯¹
            self.add_to_history("user", question)
            self.add_to_history("assistant", answer)
            
            if verbose:
                cleaned_count = len(self.llm_service.chat_history) - history_start_length - 2
                print(f"\nğŸ’¾ ChatServiceï¼šåªä¿å­˜é—®ç­”ï¼ˆæ¸…é™¤äº† {cleaned_count} æ¡ä¸­é—´è¿‡ç¨‹ï¼‰")
        else:
            # âŒ ä¿ç•™æ‰€æœ‰æ€è€ƒè¿‡ç¨‹
            # Agent å·²ç»æ·»åŠ äº†æ‰€æœ‰ä¸­é—´å†å²åˆ° llm_service
            self.add_to_history("user", question)
            self.add_to_history("assistant", answer)
            
            if verbose:
                total_count = len(self.llm_service.chat_history) - history_start_length
                print(f"\nğŸ’¾ ChatServiceï¼šä¿ç•™å®Œæ•´æ€è€ƒè¿‡ç¨‹ï¼ˆå…± {total_count} æ¡ï¼‰")
        
        return answer


    def chat(
        self,
        user_message: Optional[str] = None,
        messages: Optional[List[Dict[str, str]]] = None,
        context: Optional[str] = None,
        stream: bool = True,
        auto_add_to_history: bool = True,
        use_agent: bool = False,
        agent_tools: Optional[Dict[str, Callable]] = None,
        save_only_answer: bool = True,
        max_iterations: int = 5,
        verbose: bool = True,
        **kwargs
    ):
        """
        å¯¹è¯ï¼ˆè‡ªåŠ¨ç®¡ç†å†å²è®°å½•ï¼‰
        
        ğŸ”¥ ä¼˜åŒ–ï¼šå®Œå…¨è‡ªåŠ¨åŒ–çš„å¯¹è¯æµç¨‹
        1. è‡ªåŠ¨ä½¿ç”¨å†…éƒ¨å†å²è®°å½•
        2. è‡ªåŠ¨æ·»åŠ ç”¨æˆ·æ¶ˆæ¯å’Œ AI å›å¤åˆ°å†å²
        3. è‡ªåŠ¨å¤„ç†æ€»ç»“
        4. æ”¯æŒ ReAct Agentï¼ˆå·¥å…·è°ƒç”¨ï¼‰ğŸ†•
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯ï¼ˆç®€åŒ–ç”¨æ³•ï¼Œæ¨èï¼‰
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼ˆé«˜çº§ç”¨æ³•ï¼Œç”¨äºå®Œå…¨æ§åˆ¶ï¼‰
            context: é¢å¤–ä¸Šä¸‹æ–‡
            stream: æ˜¯å¦æµå¼è¿”å›ï¼ˆuse_agent=True æ—¶å¿½ç•¥ï¼Œæ€»æ˜¯è¿”å› strï¼‰
            auto_add_to_history: æ˜¯å¦è‡ªåŠ¨æ·»åŠ åˆ°å†å²è®°å½•ï¼ˆé»˜è®¤ Trueï¼‰
            
            use_agent: æ˜¯å¦ä½¿ç”¨ ReAct Agent è¿›è¡Œå·¥å…·è°ƒç”¨ï¼ˆé»˜è®¤ Falseï¼‰ğŸ†•
            agent_tools: Agent å¯ç”¨çš„å·¥å…·å­—å…¸ {tool_name: tool_function}ï¼ˆuse_agent=True æ—¶å¿…éœ€ï¼‰ğŸ†•
            save_only_answer: Agent æ¨¡å¼ä¸‹ï¼Œæ˜¯å¦åªä¿å­˜æœ€ç»ˆç­”æ¡ˆï¼ˆé»˜è®¤ Trueï¼Œæ¨èï¼‰ğŸ†•
                            True: åªä¿å­˜ question å’Œ answer
                            False: ä¿å­˜æ‰€æœ‰ Thoughtã€Actionã€Observation
            max_iterations: Agent æœ€å¤§æ¨ç†è½®æ•°ï¼ˆé»˜è®¤ 5ï¼‰ğŸ†•
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼ˆé»˜è®¤ Trueï¼‰ğŸ†•
            
            **kwargs: å…¶ä»–å‚æ•°
            
        Yields/Returns:
            - æ™®é€šæ¨¡å¼ï¼ˆuse_agent=Falseï¼‰ï¼š
                - stream=True: Generator[str]ï¼ˆæµå¼å›å¤ï¼‰
                - stream=False: strï¼ˆå®Œæ•´å›å¤ï¼‰
            - Agent æ¨¡å¼ï¼ˆuse_agent=Trueï¼‰ï¼šstrï¼ˆæ€»æ˜¯è¿”å›å®Œæ•´å›å¤ï¼‰
            
        ç¤ºä¾‹:
            # âœ… æ™®é€šå¯¹è¯ï¼ˆæµå¼ï¼‰
            for chunk in chat_service.chat("ä½ å¥½"):
                print(chunk, end="")
            
            # âœ… Agent å¯¹è¯ï¼ˆå·¥å…·è°ƒç”¨ï¼‰ğŸ†•
            from pkg.agent_tools import knowledge_search
            
            answer = chat_service.chat(
                user_message="å¥–å­¦é‡‘è¯„å®šæ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ",
                use_agent=True,
                agent_tools={"knowledge_search": knowledge_search}
            )
            print(answer)
            
            # âœ… é«˜çº§ç”¨æ³•ï¼ˆå®Œå…¨æ§åˆ¶ï¼Œä¸è‡ªåŠ¨æ·»åŠ å†å²ï¼‰
            response = chat_service.chat(
                messages=[{"role": "user", "content": "ä½ å¥½"}],
                auto_add_to_history=False
            )
        
        Note:
            - Agent æ¨¡å¼æ€»æ˜¯éæµå¼è¿”å›
            - Agent æ¨¡å¼éœ€è¦æä¾› agent_tools
            - æ¨èä½¿ç”¨ save_only_answer=True ä¿æŒå†å²ç®€æ´
        """
        # ğŸ†• Agent æ¨¡å¼ï¼šä½¿ç”¨ ReAct Agent è¿›è¡Œå·¥å…·è°ƒç”¨
        if use_agent:
            if not user_message:
                raise ValueError("Agent æ¨¡å¼éœ€è¦æä¾› user_message")
            if not agent_tools:
                raise ValueError("Agent æ¨¡å¼éœ€è¦æä¾› agent_tools")
            
            return self._chat_with_agent(
                question=user_message,
                agent_tools=agent_tools,
                save_only_answer=save_only_answer,
                max_iterations=max_iterations,
                verbose=verbose
            )
        
        # æ™®é€šæ¨¡å¼ï¼šç›´æ¥ LLM å¯¹è¯
        # æå–ç”¨æˆ·æ¶ˆæ¯ï¼ˆç”¨äºå†å²è®°å½•ï¼‰
        extracted_user_message = None
        if user_message:
            extracted_user_message = user_message
        elif messages and auto_add_to_history:
            # ä» messages ä¸­æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            for msg in reversed(messages):
                if msg.get("role") == "user":
                    extracted_user_message = msg.get("content")
                    break
        
        # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šåªä¼ é€’å…¶ä¸­ä¸€ä¸ªå‚æ•°ç»™åº•å±‚ LLM
        # é¿å…å‚æ•°å†²çª
        if user_message:
            # ç®€åŒ–ç”¨æ³•ï¼šåªä¼  user_message
            result_generator = self.llm_service.chat(
                user_message=user_message,
                context=context,
                stream=stream,
                use_history=True,  # ğŸ”¥ è‡ªåŠ¨ä½¿ç”¨å†…éƒ¨å†å²
                **kwargs
            )
        else:
            # é«˜çº§ç”¨æ³•ï¼šä¼  messagesï¼ˆä¸ä¼  user_messageï¼‰
            result_generator = self.llm_service.chat(
                messages=messages,
                context=context,
                stream=stream,
                use_history=True,  # ğŸ”¥ è‡ªåŠ¨ä½¿ç”¨å†…éƒ¨å†å²
                **kwargs
            )
        
        # å¦‚æœéœ€è¦è‡ªåŠ¨æ·»åŠ åˆ°å†å²
        if auto_add_to_history and extracted_user_message:
            # å…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            self.add_to_history("user", extracted_user_message)
            
            if stream:
                # æµå¼è¿”å›ï¼šéœ€è¦æ”¶é›†å®Œæ•´å›å¤åå†æ·»åŠ 
                def response_generator():
                    full_response = ""
                    try:
                        for chunk in result_generator:
                            full_response += chunk
                            yield chunk
                    finally:
                        # æ·»åŠ  AI å›å¤åˆ°å†å²ï¼ˆå³ä½¿å‡ºé”™ä¹Ÿä¼šæ‰§è¡Œï¼‰
                        if full_response:
                            self.add_to_history("assistant", full_response)
                
                return response_generator()
            else:
                # éæµå¼ï¼šç›´æ¥æ·»åŠ å®Œæ•´å›å¤
                response = result_generator
                self.add_to_history("assistant", response)
                return response
        else:
            # ä¸è‡ªåŠ¨æ·»åŠ å†å²ï¼Œç›´æ¥è¿”å›
            return result_generator
    
    def add_to_history(self, role: str, content: str):
        """
        æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•
        
        ğŸ”¥ ä¼˜åŒ–ï¼šåªä¼šæ ‡è®°æ˜¯å¦éœ€è¦æ€»ç»“ï¼Œä¸ä¼šç«‹å³æ‰§è¡Œ
        çœŸæ­£çš„æ€»ç»“å‘ç”Ÿåœ¨ä¸‹æ¬¡ chat() è°ƒç”¨æ—¶
        
        Args:
            role: è§’è‰² (user/assistant/system)
            content: å†…å®¹
        """
        self.llm_service.add_to_history(role, content)
    
    def get_history(self) -> List[Dict[str, str]]:
        """è·å–å†å²è®°å½•"""
        return self.llm_service.get_history()
    
    def clear_history(self):
        """æ¸…ç©ºå†å²è®°å½•"""
        self.llm_service.clear_history()
        print("âœ“ å†å²è®°å½•å·²æ¸…ç©º")
    
    def get_history_stats(self) -> Dict[str, Any]:
        """è·å–å†å²è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.llm_service.get_history_stats()
        
        # æ·»åŠ ä¼šè¯ä¿¡æ¯
        stats["session_id"] = self.session_id
        stats["user_id"] = self.user_id
        
        return stats
    
    def get_info(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ä¿¡æ¯"""
        info = self.llm_service.get_info()
        
        # æ·»åŠ  ChatService å±‚çš„ä¿¡æ¯
        info["chat_service"] = {
            "session_id": self.session_id,
            "user_id": self.user_id
        }
        
        return info