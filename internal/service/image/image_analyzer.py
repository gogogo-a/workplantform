"""
å›¾ç‰‡åˆ†æå™¨
è´Ÿè´£å›¾ç‰‡çš„ OCR è¯†åˆ«å’Œå¤šæ¨¡æ€åˆ†æï¼ˆLLaVAï¼‰
ä»åŸæœ‰çš„ image_service.py è¿ç§»
"""
from typing import Dict, Any, AsyncGenerator
from PIL import Image, ImageEnhance
import io
import base64

from log import logger
from pkg.constants.constants import OLLAMA_BASE_URL, ENABLE_VISION, VISION_MODEL


class ImageAnalyzer:
    """å›¾ç‰‡åˆ†æå™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–å›¾ç‰‡åˆ†æå™¨"""
        if not hasattr(self, '_initialized'):
            self._initialized = True
            self._vision_enabled = ENABLE_VISION
            self._vision_model = VISION_MODEL
    
    def ocr_image(self, image_bytes: bytes, filename: str) -> str:
        """
        OCR æ–‡å­—è¯†åˆ«
        
        Args:
            image_bytes: å›¾ç‰‡å­—èŠ‚æµ
            filename: æ–‡ä»¶å
        
        Returns:
            è¯†åˆ«å‡ºçš„æ–‡å­—
        """
        try:
            import pytesseract
            
            # ä»å­—èŠ‚æµåŠ è½½å›¾ç‰‡
            image = Image.open(io.BytesIO(image_bytes))
            
            # å›¾ç‰‡é¢„å¤„ç†ï¼ˆæé«˜ OCR å‡†ç¡®ç‡ï¼‰
            # 1. è½¬ä¸ºç°åº¦å›¾
            if image.mode != 'L':
                image = image.convert('L')
            
            # 2. å¢å¼ºå¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(2.0)
            
            # 3. ä½¿ç”¨ Tesseract OCR è¯†åˆ«ï¼ˆä¸­è‹±æ–‡ï¼‰
            text = pytesseract.image_to_string(
                image,
                lang='chi_sim+eng',  # ä¸­æ–‡ç®€ä½“ + è‹±æ–‡
                config='--psm 3'     # å…¨è‡ªåŠ¨é¡µé¢åˆ†å‰²
            )
            
            # æ¸…ç†è¯†åˆ«ç»“æœ
            text = text.strip()
            
            if not text:
                logger.debug(f"å›¾ç‰‡ OCR è¯†åˆ«ç»“æœä¸ºç©º: {filename}")
                return "ï¼ˆå›¾ç‰‡ä¸­æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹ï¼‰"
            
            return text
            
        except ImportError:
            logger.warning("âš ï¸ pytesseract æœªå®‰è£…ï¼Œè·³è¿‡ OCR è¯†åˆ«")
            return "ï¼ˆç³»ç»Ÿæœªå®‰è£… OCR ç»„ä»¶ï¼‰"
        except Exception as e:
            logger.error(f"âŒ OCR è¯†åˆ«å¤±è´¥: {filename}, error={e}")
            return f"ï¼ˆOCR è¯†åˆ«å¤±è´¥ï¼š{str(e)}ï¼‰"
    
    def llava_analyze_stream(self, image_bytes: bytes, filename: str):
        """
        ä½¿ç”¨ LLaVA (Ollama) æ¨¡å‹åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆæµå¼ï¼‰
        
        Args:
            image_bytes: å›¾ç‰‡å­—èŠ‚æµ
            filename: æ–‡ä»¶å
        
        Yields:
            str: å›¾ç‰‡å†…å®¹æè¿°ç‰‡æ®µ
        """
        try:
            import ollama
            
            logger.info(f"ğŸ” ä½¿ç”¨ LLaVA æ¨¡å‹æµå¼åˆ†æå›¾ç‰‡: {filename}")
            
            # åŠ è½½å›¾ç‰‡è·å–å°ºå¯¸ä¿¡æ¯
            image = Image.open(io.BytesIO(image_bytes))
            image_width, image_height = image.size
            
            # å°†å›¾ç‰‡è½¬æ¢ä¸º base64
            image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            # æ„å»ºç»¼åˆæç¤ºè¯
            prompt = """è¯·ç²¾ç®€çš„æè¿°è¿™å¼ å›¾ç‰‡ï¼ŒåŒ…æ‹¬ï¼š
1. å›¾ç‰‡çš„ä¸»è¦å†…å®¹å’Œåœºæ™¯
2. èƒ½çœ‹åˆ°çš„ç‰©ä½“å’Œå…ƒç´ 
3. å›¾ç‰‡ä¸­æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…
4. æ•´ä½“çš„é£æ ¼å’Œæ°›å›´

Please provide a simple description in Chinese."""
            
            # è°ƒç”¨ Ollama LLaVAï¼ˆæµå¼ï¼‰
            full_description = ""
            for chunk in ollama.chat(
                model=self._vision_model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_base64]
                }],
                stream=True
            ):
                content = chunk['message']['content']
                full_description += content
                yield content
            
            if not full_description.strip():
                yield self._simple_vision_analysis(image_bytes, filename)
            
        except ImportError:
            logger.error("âŒ ollama åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install ollama")
            yield self._simple_vision_analysis(image_bytes, filename)
        except Exception as e:
            logger.error(f"âŒ LLaVA åˆ†æå¤±è´¥: {filename}, error={e}", exc_info=True)
            yield self._simple_vision_analysis(image_bytes, filename)
    
    def _simple_vision_analysis(self, image_bytes: bytes, filename: str) -> str:
        """
        ç®€å•çš„å›¾ç‰‡åˆ†æï¼ˆåŸºäº PIL æå–çš„å›¾ç‰‡ç‰¹å¾ï¼‰
        
        Args:
            image_bytes: å›¾ç‰‡å­—èŠ‚æµ
            filename: æ–‡ä»¶å
        
        Returns:
            å›¾ç‰‡æè¿°
        """
        try:
            import numpy as np
            
            # åŠ è½½å›¾ç‰‡
            image = Image.open(io.BytesIO(image_bytes))
            
            # è½¬æ¢ä¸ºRGB
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # æå–åŸºæœ¬ç‰¹å¾
            width, height = image.size
            aspect_ratio = width / height if height > 0 else 1
            
            # åˆ†æä¸»è‰²è°ƒ
            img_array = np.array(image.resize((100, 100)))
            avg_color = img_array.mean(axis=(0, 1))
            r, g, b = avg_color
            
            # åˆ¤æ–­è‰²è°ƒ
            if r > 200 and g > 200 and b > 200:
                color_desc = "æ•´ä½“åäº®è‰²è°ƒ"
            elif r < 50 and g < 50 and b < 50:
                color_desc = "æ•´ä½“åæš—è‰²è°ƒ"
            elif r > g and r > b:
                color_desc = "æ•´ä½“åæš–è‰²è°ƒï¼ˆçº¢è‰²ç³»ï¼‰"
            elif b > r and b > g:
                color_desc = "æ•´ä½“åå†·è‰²è°ƒï¼ˆè“è‰²ç³»ï¼‰"
            elif g > r and g > b:
                color_desc = "æ•´ä½“åç»¿è‰²è°ƒ"
            else:
                color_desc = "è‰²è°ƒå‡è¡¡"
            
            # åˆ¤æ–­å›¾ç‰‡æ–¹å‘
            if aspect_ratio > 1.5:
                orientation = "æ¨ªå‘æ„å›¾"
            elif aspect_ratio < 0.66:
                orientation = "çºµå‘æ„å›¾"
            else:
                orientation = "æ–¹å½¢æ„å›¾"
            
            description = f"""è¿™æ˜¯ä¸€å¼  {width}x{height} åƒç´ çš„{orientation}å›¾ç‰‡ã€‚
{color_desc}ã€‚

ğŸ’¡ æç¤ºï¼šå½“å‰ä½¿ç”¨çš„æ˜¯åŸºç¡€å›¾ç‰‡åˆ†æï¼Œä»…èƒ½è¯†åˆ«å›¾ç‰‡çš„åŸºæœ¬ç‰¹å¾ã€‚
å¦‚éœ€æ›´è¯¦ç»†çš„ç‰©ä½“è¯†åˆ«ã€åœºæ™¯ç†è§£ï¼Œå»ºè®®å¯ç”¨ LLaVA æ¨¡å‹ã€‚"""
            
            return description
            
        except ImportError:
            logger.warning("âš ï¸ numpy æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œå›¾ç‰‡ç‰¹å¾åˆ†æ")
            return "ï¼ˆå›¾ç‰‡ç‰¹å¾åˆ†æéœ€è¦å®‰è£… numpyï¼‰"
        except Exception as e:
            logger.error(f"âŒ ç®€å•è§†è§‰åˆ†æå¤±è´¥: {filename}, error={e}")
            return f"ï¼ˆå›¾ç‰‡åˆ†æå¤±è´¥ï¼š{str(e)}ï¼‰"
    
    async def analyze_image_stream(
        self,
        image_bytes: bytes,
        filename: str
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆOCR + LLaVAï¼‰
        
        Args:
            image_bytes: å›¾ç‰‡å­—èŠ‚æµ
            filename: æ–‡ä»¶å
        
        Yields:
            Dict: åˆ†æè¿›åº¦äº‹ä»¶
        """
        try:
            # è·å–å›¾ç‰‡åŸºæœ¬ä¿¡æ¯
            image = Image.open(io.BytesIO(image_bytes))
            image_info = {
                "width": image.width,
                "height": image.height,
                "format": image.format or "Unknown"
            }
            
            result = {
                "ocr_text": "",
                "vision_description": "",
                "image_info": image_info,
                "combined_content": ""
            }
            
            # 1. OCR æ–‡å­—è¯†åˆ«
            yield {
                "event": "thought",
                "data": {"content": "ğŸ“ æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼ˆOCRï¼‰...\n"}
            }
            
            try:
                ocr_text = self.ocr_image(image_bytes, filename)
                result["ocr_text"] = ocr_text
                
                if ocr_text and ocr_text != "ï¼ˆå›¾ç‰‡ä¸­æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹ï¼‰":
                    yield {
                        "event": "thought",
                        "data": {"content": f"âœ… OCR è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ°æ–‡å­—ï¼š\n```\n{ocr_text}\n```\n\n"}
                    }
                else:
                    yield {
                        "event": "thought",
                        "data": {"content": "âš ï¸ å›¾ç‰‡ä¸­æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹\n\n"}
                    }
            except Exception as e:
                logger.error(f"OCR è¯†åˆ«å¤±è´¥: {e}")
                yield {
                    "event": "thought",
                    "data": {"content": f"âš ï¸ OCR è¯†åˆ«å¤±è´¥: {str(e)}\n\n"}
                }
            
            # 2. LLaVA å¤šæ¨¡æ€å›¾ç‰‡å†…å®¹è¯†åˆ«ï¼ˆæµå¼è¾“å‡ºï¼‰
            yield {
                "event": "thought",
                "data": {"content": "ğŸ¤– æ­£åœ¨ä½¿ç”¨ LLaVA åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆç‰©ä½“ã€åœºæ™¯è¯†åˆ«ï¼‰...\n\n"}
            }
            
            try:
                vision_desc_full = ""
                
                for chunk in self.llava_analyze_stream(image_bytes, filename):
                    vision_desc_full += chunk
                    yield {
                        "event": "thought",
                        "data": {"content": chunk}
                    }
                
                result["vision_description"] = vision_desc_full
                
                yield {
                    "event": "thought",
                    "data": {"content": f"\n\nâœ… å›¾ç‰‡åˆ†æå®Œæˆ\n\n"}
                }
                
            except Exception as e:
                logger.error(f"LLaVA åˆ†æå¤±è´¥: {e}")
                yield {
                    "event": "thought",
                    "data": {"content": f"âš ï¸ å›¾ç‰‡å†…å®¹è¯†åˆ«å¤±è´¥: {str(e)}\n\n"}
                }
            
            # 3. ç»¼åˆå†…å®¹æè¿°
            combined_parts = []
            
            if result["vision_description"]:
                combined_parts.append(f"ã€å›¾ç‰‡å†…å®¹ - LLaVA åˆ†æã€‘\n{result['vision_description']}")
            
            if result["ocr_text"] and result["ocr_text"] != "ï¼ˆå›¾ç‰‡ä¸­æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹ï¼‰":
                combined_parts.append(f"ã€å›¾ç‰‡ä¸­çš„æ–‡å­— - OCR è¯†åˆ«ã€‘\n{result['ocr_text']}")
            
            if not combined_parts:
                combined_parts.append("ï¼ˆå›¾ç‰‡åˆ†ææœªå¾—åˆ°æœ‰æ•ˆä¿¡æ¯ï¼‰")
            
            result["combined_content"] = "\n\n".join(combined_parts)
            
            # è¿”å›å®Œæ•´ç»“æœ
            yield {
                "event": "image_analysis_complete",
                "data": result
            }
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡åˆ†æå¤±è´¥: {filename}, error={e}", exc_info=True)
            yield {
                "event": "thought",
                "data": {"content": f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥ï¼š{str(e)}"}
            }
            yield {
                "event": "image_analysis_complete",
                "data": {"combined_content": f"ï¼ˆå›¾ç‰‡åˆ†æå¤±è´¥ï¼š{str(e)}ï¼‰"}
            }


# åˆ›å»ºå…¨å±€å•ä¾‹
image_analyzer = ImageAnalyzer()
