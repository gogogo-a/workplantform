"""
æ–‡æ¡£æœåŠ¡ä¸šåŠ¡é€»è¾‘å±‚
å¤„ç†æ–‡æ¡£çš„ä¸Šä¼ ã€æŸ¥è¯¢ã€åˆ é™¤ç­‰ä¸šåŠ¡
"""
import os
import uuid as uuid_module
from typing import Dict, Any, Optional
from pathlib import Path
from fastapi import UploadFile
from pymilvus import Collection

from internal.model.document import DocumentModel
from internal.db.milvus import milvus_client
from internal.document_client.document_processor import document_processor
from internal.document_client.config_loader import config
from pkg.constants.constants import MILVUS_COLLECTION_NAME
from log import logger


class DocumentService:
    """æ–‡æ¡£æœåŠ¡ç±»"""
    
    def __init__(self):
        self.upload_dir = Path("uploads")
        self.upload_dir.mkdir(exist_ok=True)
        self.collection_name = MILVUS_COLLECTION_NAME
    
    async def upload_document(
        self,
        file: UploadFile,
        permission: int = 0,
        uploader_id: str = None,
        uploader_name: str = None
    ):
        """
        ä¸Šä¼ æ–‡æ¡£å¹¶å¼‚æ­¥å¤„ç†
        
        Args:
            file: ä¸Šä¼ çš„æ–‡ä»¶
            permission: æ–‡æ¡£æƒé™ï¼ˆ0=æ™®é€šç”¨æˆ·å¯è§ï¼Œ1=ä»…ç®¡ç†å‘˜å¯è§ï¼‰
            uploader_id: ä¸Šä¼ è€…ID
            uploader_name: ä¸Šä¼ è€…åç§°
            
        Returns:
            tuple: (message, ret, data) - message: æç¤ºä¿¡æ¯, ret: è¿”å›ç (0æˆåŠŸ/-1å¤±è´¥), data: æ–‡æ¡£ä¿¡æ¯
        """
        try:
            from datetime import datetime
            # 1. ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            file_uuid = str(uuid_module.uuid4())
            file_extension = Path(file.filename).suffix
            new_filename = f"{file_uuid}{file_extension}"
            file_path = self.upload_dir / new_filename
            
            # 2. ä¿å­˜æ–‡ä»¶
            file_content = await file.read()
            with open(file_path, "wb") as f:
                f.write(file_content)
            
            file_size = len(file_content)
            logger.info(f"æ–‡ä»¶å·²ä¿å­˜: {file.filename} â†’ {file_path}, å¤§å°: {file_size} bytes")
            
            # 3. è§£ææ–‡æ¡£å†…å®¹
            from pkg.utils.document_utils import load_document
            
            try:
                loaded_docs = load_document(str(file_path))
                parsed_content = "\n\n".join([doc["content"] for doc in loaded_docs])
                page_count = len(loaded_docs)
                logger.info(f"æ–‡æ¡£å†…å®¹å·²è§£æ: {file.filename}, é¡µæ•°: {page_count}, å†…å®¹é•¿åº¦: {len(parsed_content)}")
            except Exception as e:
                logger.warning(f"æ–‡æ¡£å†…å®¹è§£æå¤±è´¥: {e}, å°†ä½¿ç”¨ç©ºå†…å®¹")
                parsed_content = ""
                page_count = 0
            
            # 4. ä¿å­˜æ–‡æ¡£ä¿¡æ¯åˆ° MongoDBï¼ˆåˆå§‹çŠ¶æ€ï¼šæœªå¤„ç†ï¼‰
            upload_time = datetime.now()
            doc_model = DocumentModel(
                uuid=file_uuid,
                name=file.filename,
                content=parsed_content,  # å­˜å‚¨è§£æåçš„æ–‡æœ¬å†…å®¹
                page=page_count,
                url=f"/uploads/{new_filename}",
                size=file_size,
                status=0,  # 0.æœªå¤„ç†
                permission=permission,  # ğŸ”¥ æ–‡æ¡£æƒé™
                extra_data={  # ğŸ”¥ é¢å¤–æ•°æ®
                    "uploader_id": uploader_id,
                    "uploader_name": uploader_name,
                    "upload_time": upload_time.isoformat(),
                    "file_extension": file_extension
                }
            )
            await doc_model.insert()
            
            logger.info(f"æ–‡æ¡£å·²ä¿å­˜åˆ° MongoDB: {file_uuid}, çŠ¶æ€: æœªå¤„ç†")
            
            # 5. æäº¤åˆ° Kafka å¼‚æ­¥å¤„ç†ï¼ˆEmbeddingï¼‰
            task = {
                "task_type": "file",
                "file_path": str(file_path),
                "document_uuid": file_uuid,
                "permission": permission,  # ğŸ”¥ ä¼ é€’æƒé™ä¿¡æ¯
                "metadata": {
                    "filename": file.filename,
                    "source": "api_upload",
                    "permission": permission,  # ğŸ”¥ åœ¨å…ƒæ•°æ®ä¸­ä¹Ÿæ·»åŠ æƒé™
                    "uploader_id": uploader_id,
                    "uploader_name": uploader_name
                }
            }
            
            submit_success = document_processor.submit_task(task)
            
            if not submit_success:
                logger.error(f"ä»»åŠ¡æäº¤å¤±è´¥: {file_uuid}")
                # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†å¤±è´¥
                doc_model.status = 3  # 3.å¤„ç†å¤±è´¥
                await doc_model.save()
                logger.info(f"æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°: {file_uuid} -> å¤„ç†å¤±è´¥")
                
                data = {
                    "uuid": file_uuid,
                    "name": file.filename,
                    "status": 3,
                    "status_text": "å¤„ç†å¤±è´¥"
                }
                return "æ–‡æ¡£ä¿å­˜æˆåŠŸï¼Œä½†å¤„ç†ä»»åŠ¡æäº¤å¤±è´¥", -1, data
            
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            doc_model.status = 1  # 1.å¤„ç†ä¸­
            await doc_model.save()
            logger.info(f"æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°: {file_uuid} -> å¤„ç†ä¸­")
            logger.info(f"æ–‡æ¡£å¤„ç†ä»»åŠ¡å·²æäº¤: {file_uuid}")
            
            data = {
                "uuid": file_uuid,
                "name": file.filename,
                "size": file_size,
                "page": page_count,
                "url": f"/uploads/{new_filename}",
                "content": parsed_content[:500] + "..." if len(parsed_content) > 500 else parsed_content,  # è¿”å›å‰500å­—ç¬¦
                "content_length": len(parsed_content),
                "status": 1,
                "status_text": "å¤„ç†ä¸­",
                "permission": permission,  # ğŸ”¥ è¿”å›æƒé™ä¿¡æ¯
                "message": "æ–‡æ¡£å·²æäº¤å¤„ç†ï¼Œåå°æ­£åœ¨è¿›è¡Œ Embedding"
            }
            return "ä¸Šä¼ æˆåŠŸ", 0, data
            
        except Exception as e:
            logger.error(f"ä¸Šä¼ æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
            return f"ä¸Šä¼ å¤±è´¥: {str(e)}", -1, None
    
    async def get_document_detail(self, document_uuid: str):
        """
        è·å–æ–‡æ¡£è¯¦æƒ…
        
        Args:
            document_uuid: æ–‡æ¡£UUID
            
        Returns:
            tuple: (message, ret, data) - message: æç¤ºä¿¡æ¯, ret: è¿”å›ç , data: æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
        """
        try:
            # 1. ä» MongoDB è·å–æ–‡æ¡£åŸºæœ¬ä¿¡æ¯
            doc = await DocumentModel.find_one(DocumentModel.uuid == document_uuid)
            
            if not doc:
                return "æ–‡æ¡£ä¸å­˜åœ¨", -2, None
            
            # 2. ä» Milvus è·å– chunk_count
            chunk_count = await self._get_chunk_count_from_milvus(document_uuid)
            
            # 3. çŠ¶æ€æ–‡æœ¬æ˜ å°„
            status_text_map = {
                0: "æœªå¤„ç†",
                1: "å¤„ç†ä¸­",
                2: "å¤„ç†å®Œæˆ",
                3: "å¤„ç†å¤±è´¥"
            }
            
            data = {
                "uuid": doc.uuid,
                "name": doc.name,
                "size": doc.size,
                "page": doc.page,
                "url": doc.url,
                "content": doc.content,  # è¿”å›å®Œæ•´å†…å®¹
                "content_length": len(doc.content) if doc.content else 0,
                "status": doc.status,
                "status_text": status_text_map.get(doc.status, "æœªçŸ¥"),
                "permission": doc.permission,  # ğŸ”¥ è¿”å›æƒé™ä¿¡æ¯
                "extra_data": doc.extra_data,  # ğŸ”¥ è¿”å›é¢å¤–æ•°æ®ï¼ˆä¸Šä¼ è€…ã€å¤„ç†æ—¶é—´ç­‰ï¼‰
                "uploaded_at": doc.create_at.isoformat() if doc.create_at else None,
                "updated_at": doc.update_at.isoformat() if doc.update_at else None,  # ğŸ”¥ è¿”å›æ›´æ–°æ—¶é—´
                "chunk_count": chunk_count
            }
            return "æŸ¥è¯¢æˆåŠŸ", 0, data
            
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
            return f"æŸ¥è¯¢å¤±è´¥: {str(e)}", -1, None
    
    async def delete_document(self, document_uuid: str):
        """
        åˆ é™¤æ–‡æ¡£ï¼ˆMongoDB + Milvus + ç‰©ç†æ–‡ä»¶ï¼‰
        
        Args:
            document_uuid: æ–‡æ¡£UUID
            
        Returns:
            tuple: (message, ret) - message: æç¤ºä¿¡æ¯, ret: è¿”å›ç 
        """
        try:
            # 1. æŸ¥è¯¢æ–‡æ¡£
            doc = await DocumentModel.find_one(DocumentModel.uuid == document_uuid)
            
            if not doc:
                return "æ–‡æ¡£ä¸å­˜åœ¨", -2
            
            # 2. åˆ é™¤ MongoDB è®°å½•
            await doc.delete()
            logger.info(f"MongoDB æ–‡æ¡£å·²åˆ é™¤: {document_uuid}")
            
            # 3. åˆ é™¤ Milvus å‘é‡æ•°æ®
            deleted_count = self._delete_from_milvus(document_uuid)
            logger.info(f"Milvus å‘é‡å·²åˆ é™¤: {document_uuid}, æ•°é‡: {deleted_count}")
            
            # 4. åˆ é™¤ç‰©ç†æ–‡ä»¶
            file_path = Path(doc.url.lstrip('/'))
            if file_path.exists():
                file_path.unlink()
                logger.info(f"ç‰©ç†æ–‡ä»¶å·²åˆ é™¤: {file_path}")
            
            return f"æ–‡æ¡£å·²åˆ é™¤ï¼ˆåŒ…å« {deleted_count} ä¸ªå‘é‡å—ï¼‰", 0
            
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
            return f"åˆ é™¤å¤±è´¥: {str(e)}", -1
    
    async def get_document_list(
        self, 
        page: int = 1, 
        page_size: int = 10, 
        keyword: Optional[str] = None
    ):
        """
        è·å–æ–‡æ¡£åˆ—è¡¨ï¼ˆåˆ†é¡µ + æœç´¢ï¼‰
        
        Args:
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            tuple: (message, ret, data) - message: æç¤ºä¿¡æ¯, ret: è¿”å›ç , data: æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # 1. æ„å»ºæŸ¥è¯¢æ¡ä»¶
            skip = (page - 1) * page_size
            
            if keyword:
                # ä½¿ç”¨åç§°æ¨¡ç³Šæœç´¢
                query = {"name": {"$regex": keyword, "$options": "i"}}
                total = await DocumentModel.find(query).count()
                docs = await DocumentModel.find(query).skip(skip).limit(page_size).to_list()
            else:
                total = await DocumentModel.count()
                docs = await DocumentModel.find_all().skip(skip).limit(page_size).to_list()
            
            # 2. ä¸ºæ¯ä¸ªæ–‡æ¡£è·å– chunk_countï¼ˆä» Milvusï¼‰
            status_text_map = {
                0: "æœªå¤„ç†",
                1: "å¤„ç†ä¸­",
                2: "å¤„ç†å®Œæˆ",
                3: "å¤„ç†å¤±è´¥"
            }
            
            document_list = []
            for doc in docs:
                chunk_count = await self._get_chunk_count_from_milvus(doc.uuid)
                document_list.append({
                    "uuid": doc.uuid,
                    "name": doc.name,
                    "size": doc.size,  # ğŸ”¥ æ·»åŠ æ–‡ä»¶å¤§å°
                    "status": doc.status,
                    "status_text": status_text_map.get(doc.status, "æœªçŸ¥"),
                    "permission": doc.permission,  # ğŸ”¥ æ·»åŠ æƒé™ä¿¡æ¯
                    "uploaded_at": doc.create_at.isoformat() if doc.create_at else None,
                    "chunk_count": chunk_count
                })
            
            data = {
                "total": total,
                "page": page,
                "page_size": page_size,
                "documents": document_list
            }
            return "æŸ¥è¯¢æˆåŠŸ", 0, data
            
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
            return f"æŸ¥è¯¢å¤±è´¥: {str(e)}", -1, None
    
    async def _get_chunk_count_from_milvus(self, document_uuid: str) -> int:
        """
        ä» Milvus æŸ¥è¯¢æŒ‡å®šæ–‡æ¡£çš„ chunk æ•°é‡
        
        Args:
            document_uuid: æ–‡æ¡£UUID
            
        Returns:
            int: chunk æ•°é‡
        """
        try:
            existing_collections = milvus_client.list_collections()
            if self.collection_name not in existing_collections:
                return 0
            
            collection = Collection(self.collection_name)
            collection.load()
            
            # æŸ¥è¯¢è¯¥æ–‡æ¡£çš„æ‰€æœ‰å‘é‡è®°å½•ï¼ˆdocument_uuid åœ¨ metadata ä¸­ï¼‰
            expr = f'metadata["document_uuid"] == "{document_uuid}"'
            results = collection.query(
                expr=expr,
                output_fields=["id"],
                limit=10000
            )
            
            return len(results)
            
        except Exception as e:
            logger.warning(f"ä» Milvus æŸ¥è¯¢ chunk_count å¤±è´¥: {e}")
            return 0
    
    async def update_document_status(
        self, 
        document_uuid: str, 
        status: int,
        page: Optional[int] = None,
        content: Optional[str] = None
    ):
        """
        æ›´æ–°æ–‡æ¡£çŠ¶æ€ï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼Œä¾› API å±‚ä½¿ç”¨ï¼‰
        
        Args:
            document_uuid: æ–‡æ¡£UUID
            status: çŠ¶æ€ç ï¼ˆ0.æœªå¤„ç†ï¼Œ1.å¤„ç†ä¸­ï¼Œ2.å¤„ç†å®Œæˆï¼Œ3.å¤„ç†å¤±è´¥ï¼‰
            page: æ–‡æ¡£é¡µæ•°ï¼ˆå¯é€‰ï¼‰
            content: æ–‡æ¡£å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            tuple: (message, ret) - message: æç¤ºä¿¡æ¯, ret: è¿”å›ç 
        """
        try:
            # 1. æŸ¥è¯¢æ–‡æ¡£
            doc = await DocumentModel.find_one(DocumentModel.uuid == document_uuid)
            
            if not doc:
                return "æ–‡æ¡£ä¸å­˜åœ¨", -2
            
            # 2. æ›´æ–°çŠ¶æ€
            status_text_map = {
                0: "æœªå¤„ç†",
                1: "å¤„ç†ä¸­",
                2: "å¤„ç†å®Œæˆ",
                3: "å¤„ç†å¤±è´¥"
            }
            
            doc.status = status
            if page is not None:
                doc.page = page
            if content is not None:
                doc.content = content
            
            await doc.save()
            
            status_text = status_text_map.get(status, "æœªçŸ¥")
            logger.info(f"æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°: {document_uuid} -> {status_text}")
            
            return f"çŠ¶æ€æ›´æ–°æˆåŠŸ: {status_text}", 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ–‡æ¡£çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
            return f"æ›´æ–°å¤±è´¥: {str(e)}", -1
    
    def update_document_status_sync(
        self, 
        document_uuid: str, 
        status: int,
        page: Optional[int] = None,
        content: Optional[str] = None,
        extra_data_update: Optional[Dict[str, Any]] = None
    ):
        """
        æ›´æ–°æ–‡æ¡£çŠ¶æ€ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œä¾› Kafka æ¶ˆè´¹è€…ä½¿ç”¨ï¼‰
        ä½¿ç”¨ pymongo ç›´æ¥æ“ä½œï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çª
        
        Args:
            document_uuid: æ–‡æ¡£UUID
            status: çŠ¶æ€ç ï¼ˆ0.æœªå¤„ç†ï¼Œ1.å¤„ç†ä¸­ï¼Œ2.å¤„ç†å®Œæˆï¼Œ3.å¤„ç†å¤±è´¥ï¼‰
            page: æ–‡æ¡£é¡µæ•°ï¼ˆå¯é€‰ï¼‰
            content: æ–‡æ¡£å†…å®¹ï¼ˆå¯é€‰ï¼‰
            extra_data_update: é¢å¤–æ•°æ®æ›´æ–°ï¼ˆå¯é€‰ï¼Œä¼šåˆå¹¶åˆ°ç°æœ‰çš„extra_dataä¸­ï¼‰
            
        Returns:
            tuple: (message, ret) - message: æç¤ºä¿¡æ¯, ret: è¿”å›ç 
        """
        try:
            from pymongo import MongoClient
            from pkg.constants.constants import MONGODB_URL, MONGODB_DATABASE
            from datetime import datetime
            
            # ä½¿ç”¨åŒæ­¥çš„ pymongo å®¢æˆ·ç«¯
            client = MongoClient(MONGODB_URL)
            db = client[MONGODB_DATABASE]
            collection = db['documents']
            
            # æŸ¥è¯¢æ–‡æ¡£
            doc = collection.find_one({"uuid": document_uuid})
            
            if not doc:
                client.close()
                return "æ–‡æ¡£ä¸å­˜åœ¨", -2
            
            # å‡†å¤‡æ›´æ–°æ•°æ®
            update_data = {"status": status, "update_at": datetime.now()}
            if page is not None:
                update_data["page"] = page
            if content is not None:
                update_data["content"] = content
            
            # ğŸ”¥ æ›´æ–° extra_dataï¼ˆåˆå¹¶æ–°æ•°æ®ï¼‰
            if extra_data_update is not None:
                existing_extra_data = doc.get("extra_data", {})
                existing_extra_data.update(extra_data_update)
                update_data["extra_data"] = existing_extra_data
            
            # æ›´æ–°æ–‡æ¡£
            result = collection.update_one(
                {"uuid": document_uuid},
                {"$set": update_data}
            )
            
            client.close()
            
            status_text_map = {
                0: "æœªå¤„ç†",
                1: "å¤„ç†ä¸­",
                2: "å¤„ç†å®Œæˆ",
                3: "å¤„ç†å¤±è´¥"
            }
            
            status_text = status_text_map.get(status, "æœªçŸ¥")
            
            if result.modified_count > 0:
                logger.info(f"æ–‡æ¡£çŠ¶æ€å·²æ›´æ–°ï¼ˆåŒæ­¥ï¼‰: {document_uuid} -> {status_text}")
                return f"çŠ¶æ€æ›´æ–°æˆåŠŸ: {status_text}", 0
            else:
                logger.warning(f"æ–‡æ¡£çŠ¶æ€æœªå˜åŒ–: {document_uuid} -> {status_text}")
                return f"æ–‡æ¡£çŠ¶æ€æœªå˜åŒ–", 0
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ–‡æ¡£çŠ¶æ€å¤±è´¥ï¼ˆåŒæ­¥ï¼‰: {e}", exc_info=True)
            return f"æ›´æ–°å¤±è´¥: {str(e)}", -1
    
    def _delete_from_milvus(self, document_uuid: str) -> int:
        """
        ä» Milvus åˆ é™¤æŒ‡å®šæ–‡æ¡£çš„æ‰€æœ‰å‘é‡
        
        Args:
            document_uuid: æ–‡æ¡£UUID
            
        Returns:
            int: åˆ é™¤çš„å‘é‡æ•°é‡
        """
        try:
            existing_collections = milvus_client.list_collections()
            if self.collection_name not in existing_collections:
                return 0
            
            collection = Collection(self.collection_name)
            collection.load()
            
            # å…ˆæŸ¥è¯¢è¯¥æ–‡æ¡£æœ‰å¤šå°‘æ¡è®°å½•ï¼ˆdocument_uuid åœ¨ metadata ä¸­ï¼‰
            expr = f'metadata["document_uuid"] == "{document_uuid}"'
            count_results = collection.query(
                expr=expr,
                output_fields=["id"],
                limit=10000
            )
            
            count = len(count_results)
            
            # åˆ é™¤
            if count > 0:
                collection.delete(expr)
                collection.flush()
            
            return count
            
        except Exception as e:
            logger.error(f"ä» Milvus åˆ é™¤å‘é‡å¤±è´¥: {e}", exc_info=True)
            return 0


# å¯¼å‡ºå•ä¾‹
document_service = DocumentService()

