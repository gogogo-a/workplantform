"""
æ¶ˆæ¯ç®¡ç†ä¸šåŠ¡é€»è¾‘ï¼ˆæ±‡æ€»å…¥å£ï¼‰
æ•´åˆå„ä¸ªæ¨¡å—ï¼š
- message: æ¶ˆæ¯ CRUDã€ä¼šè¯ç®¡ç†ã€æ–‡ä»¶å¤„ç†ã€å†å²ç®¡ç†
- ai: AI å›å¤ç”Ÿæˆã€æµå¼è§£æ
- image: å›¾ç‰‡åˆ†æ
- summary: å¯¹è¯æ€»ç»“

ä¿æŒåŸæœ‰æ¥å£ä¸å˜ï¼Œå†…éƒ¨è°ƒç”¨æ¨¡å—åŒ–çš„æœåŠ¡
"""
from typing import Tuple, Optional, Dict, Any, List, AsyncGenerator
from datetime import datetime
import time
import asyncio

from internal.db.milvus import milvus_client
from internal.rag.rag_service import rag_service
from log import logger
from pkg.constants.constants import MILVUS_COLLECTION_NAME, SUPPORTED_IMAGE_FORMATS
from internal.monitor import record_performance

# å¯¼å…¥æ¨¡å—åŒ–æœåŠ¡
from internal.service.message import (
    message_crud_service,
    session_manager,
    file_handler,
    history_manager
)
from internal.service.ai import ai_reply_service, thought_chain_store
from internal.service.ai.qa_evaluator import qa_evaluator
from internal.service.image import image_analyzer
from internal.service.summary import summary_service


class MessageService:
    """æ¶ˆæ¯ç®¡ç†æœåŠ¡ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰- æ±‡æ€»å…¥å£"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        if self._initialized:
            return
        
        self._init_rag_service()
        self._initialized = True
        logger.info("âœ… MessageService åˆå§‹åŒ–å®Œæˆ")
    
    def _init_rag_service(self):
        """åˆå§‹åŒ– RAG æ£€ç´¢æœåŠ¡"""
        try:
            from pymilvus import connections
            if not connections.has_connection("default"):
                milvus_client.connect()
            
            rag_service.collection_name = MILVUS_COLLECTION_NAME
            rag_service.initialize()
            
        except Exception as e:
            logger.warning(f"RAG æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
    
    # ==================== å…¬å…±æ¥å£ ====================
    
    async def send_message_stream(
        self,
        content: str,
        user_id: str,
        send_name: str,
        send_avatar: str,
        session_id: Optional[str] = None,
        file_type: Optional[str] = None,
        file_name: Optional[str] = None,
        file_size: Optional[str] = None,
        file_content: Optional[str] = None,
        file_bytes: Optional[bytes] = None,
        show_thinking: bool = False,
        location: Optional[str] = None,
        skip_cache: bool = False,
        regenerate_message_id: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å‘é€æ¶ˆæ¯ï¼ˆç»Ÿä¸€æµå¼è¿”å›ï¼Œæ”¯æŒæ–‡ä»¶å†…å®¹ï¼‰
        
        Args:
            content: ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼ˆä¿å­˜åˆ°æ•°æ®åº“ï¼‰
            user_id: ç”¨æˆ·ID
            send_name: å‘é€è€…æ˜µç§°
            send_avatar: å‘é€è€…å¤´åƒ
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
            file_type: æ–‡ä»¶ç±»å‹
            file_name: æ–‡ä»¶å
            file_size: æ–‡ä»¶å¤§å°
            file_content: æ–‡æ¡£æ–‡ä»¶å†…å®¹ï¼ˆå·²è§£æï¼‰
            file_bytes: å›¾ç‰‡æ–‡ä»¶å­—èŠ‚æµï¼ˆæœªè§£æï¼‰
            show_thinking: æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
            location: ç”¨æˆ·ä½ç½®ä¿¡æ¯
            skip_cache: æ˜¯å¦è·³è¿‡ç¼“å­˜ï¼ˆé‡æ–°å›ç­”æ—¶ä½¿ç”¨ï¼‰
            regenerate_message_id: é‡æ–°ç”Ÿæˆæ—¶çš„åŸæ¶ˆæ¯IDï¼ˆç”¨äºåˆ é™¤æ—§ç¼“å­˜ï¼‰
        
        Yields:
            Dict: åŒ…å«äº‹ä»¶ç±»å‹å’Œæ•°æ®çš„å­—å…¸
        """
        try:
            logger.debug(f"æ¶ˆæ¯è¯·æ±‚: user={user_id}, session={session_id}")
            
            # 1. åˆ›å»ºæˆ–è·å–ä¼šè¯
            session_id, session_name = await session_manager.create_or_get_session(
                session_id, user_id, content
            )
            
            yield {
                "event": "session_created",
                "data": {
                    "session_id": session_id,
                    "session_name": session_name
                }
            }
            
            # 2. å¤„ç†å›¾ç‰‡æ–‡ä»¶ï¼ˆæµå¼åˆ†æï¼‰
            enhanced_content = content
            
            if file_bytes and file_name:
                if file_handler.is_image_file(file_name):
                    # å›¾ç‰‡æ–‡ä»¶ï¼šæµå¼åˆ†æ
                    logger.debug(f"åˆ†æå›¾ç‰‡: {file_name}")
                    
                    yield {
                        "event": "thought",
                        "data": {"content": f"ğŸ–¼ï¸ æ­£åœ¨åˆ†æä¸Šä¼ çš„å›¾ç‰‡ï¼š{file_name}"}
                    }
                    
                    # æ‰§è¡Œå›¾ç‰‡åˆ†æ
                    image_analysis_result = None
                    async for analysis_event in image_analyzer.analyze_image_stream(file_bytes, file_name):
                        yield analysis_event
                        if analysis_event.get("event") == "image_analysis_complete":
                            image_analysis_result = analysis_event.get("data", {}).get("combined_content", "")
                    
                    # æ„å»ºå¢å¼ºå†…å®¹
                    if image_analysis_result:
                        from PIL import Image
                        import io
                        image = Image.open(io.BytesIO(file_bytes))
                        enhanced_content = f"""è¿™æ˜¯æˆ‘ä¸Šä¼ çš„å›¾ç‰‡ï¼ˆæ–‡ä»¶åï¼š{file_name}ï¼Œå°ºå¯¸ï¼š{image.width}x{image.height}ï¼‰ï¼š

{image_analysis_result}

---

æˆ‘çš„é—®é¢˜ï¼š{content}"""
                        file_content = image_analysis_result
                else:
                    # æ–‡æ¡£æ–‡ä»¶ï¼šå·²åœ¨ Controller å±‚è§£æ
                    if file_content:
                        logger.debug(f"æ–‡æ¡£æ–‡ä»¶: {file_name}, é•¿åº¦: {len(file_content)}")
                        enhanced_content = f"""è¿™æ˜¯æˆ‘ä¸Šä¼ çš„ {file_type.upper()} æ–‡ä»¶ï¼ˆæ–‡ä»¶åï¼š{file_name}ï¼‰ï¼š

{file_content}

---

æˆ‘çš„é—®é¢˜ï¼š{content}"""
            elif file_content:
                # å‘åå…¼å®¹
                enhanced_content = f"""è¿™æ˜¯æˆ‘ä¸Šä¼ çš„æ–‡ä»¶ï¼š

{file_content}

---

æˆ‘çš„é—®é¢˜ï¼š{content}"""
            
            # 3. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            user_msg = await message_crud_service.save_user_message(
                session_id, content, user_id, send_name, send_avatar,
                file_type, file_name, file_size, file_content, file_bytes, location
            )
            
            yield {
                "event": "user_message_saved",
                "data": {
                    "uuid": user_msg.uuid,
                    "content": user_msg.content
                }
            }
            
            # 4. è·å–ä¼šè¯å†å²
            history = await history_manager.get_session_history(session_id)
            
            # 5. è·å–ç”¨æˆ·æƒé™
            from internal.model.user_info import UserInfoModel
            user_info = await UserInfoModel.find_one(UserInfoModel.uuid == user_id)
            is_admin = user_info.is_admin if user_info else False
            user_permission = 1 if is_admin else 0
            
            # 5.1 å¯åŠ¨å¼‚æ­¥é—®ç­”è¯„ä¼°ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            evaluation_id = f"{session_id}:{user_msg.uuid}"
            qa_evaluator.start_evaluation(content, evaluation_id)
            
            # 5.2 å¦‚æœæ˜¯é‡æ–°å›ç­”ï¼Œåˆ é™¤æ—§çš„ç¼“å­˜
            if skip_cache and regenerate_message_id:
                from internal.model.thought_chain import ThoughtChainModel
                from internal.service.ai.similar_qa_cache import similar_qa_cache
                
                # æŸ¥æ‰¾å…³è”çš„æ€ç»´é“¾
                old_chain = await ThoughtChainModel.find_one(
                    ThoughtChainModel.message_id == regenerate_message_id
                )
                if old_chain and old_chain.is_cached:
                    await similar_qa_cache.delete_cache(old_chain.uuid)
                    logger.debug(f"å·²åˆ é™¤æ—§ç¼“å­˜: {old_chain.uuid}")
            
            # 6. æµå¼ç”Ÿæˆ AI å›å¤
            ai_reply_full = ""
            extra_data = {
                "thoughts": [],
                "actions": [],
                "observations": [],
                "documents": []
            }
            
            # æ€§èƒ½ç›‘æ§
            llm_total_start = time.time()
            current_thought_start = None
            current_action_start = None
            answer_start = None
            
            # æ·»åŠ ä½ç½®ä¿¡æ¯
            ai_input_content = enhanced_content
            if location:
                ai_input_content = f"{ai_input_content}\n\n[ç³»ç»Ÿä¿¡æ¯]\nç”¨æˆ·ä½ç½®: {location}"
            
            # è°ƒç”¨ AI å›å¤æœåŠ¡
            # ç”¨äºç¼“å­˜å‘½ä¸­æ—¶ä¿å­˜ thought_chain_id
            cached_thought_chain_id = None
            
            async for event_dict in ai_reply_service.generate_reply_stream(
                session_id, user_id, ai_input_content, history, user_permission,
                original_question=content,  # ä¼ é€’åŸå§‹é—®é¢˜ç”¨äºç›¸ä¼¼é—®é¢˜æ£€ç´¢
                skip_cache=skip_cache  # ä¼ é€’è·³è¿‡ç¼“å­˜æ ‡å¿—
            ):
                event_type = event_dict.get("event", "message")
                event_data = event_dict.get("data", {})
                event_content = event_data.get("content", "")
                
                # å¤„ç†ç¼“å­˜å‘½ä¸­äº‹ä»¶
                if event_type == "cache_hit":
                    cached_thought_chain_id = event_data.get("thought_chain_id")
                    logger.info(f"ç¼“å­˜å‘½ä¸­: thought_chain_id={cached_thought_chain_id}")
                    # ä¸å‘å‰ç«¯å‘é€ cache_hit äº‹ä»¶ï¼Œåªè®°å½•
                    continue
                
                # æ ¹æ® show_thinking å‚æ•°å†³å®šæ˜¯å¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹
                elif event_type == "thought":
                    if current_thought_start is None:
                        current_thought_start = time.time()
                    extra_data["thoughts"].append(event_content)
                    if show_thinking:
                        yield event_dict
                        
                elif event_type == "action":
                    if current_thought_start is not None:
                        think_duration = time.time() - current_thought_start
                        record_performance('llm_think', f'æ€è€ƒæ­¥éª¤{len(extra_data["thoughts"])}', think_duration,
                                         thought_content=extra_data["thoughts"][-1][:100] if extra_data["thoughts"] else "")
                        current_thought_start = None
                    current_action_start = time.time()
                    extra_data["actions"].append(event_content)
                    if show_thinking:
                        yield event_dict
                        
                elif event_type == "observation":
                    if current_action_start is not None:
                        action_duration = time.time() - current_action_start
                        record_performance('llm_action', f'åŠ¨ä½œæ­¥éª¤{len(extra_data["actions"])}', action_duration,
                                         action_content=extra_data["actions"][-1][:100] if extra_data["actions"] else "")
                        current_action_start = None
                    extra_data["observations"].append(event_content)
                    if show_thinking:
                        yield event_dict
                        
                elif event_type == "answer_chunk":
                    if answer_start is None:
                        answer_start = time.time()
                    ai_reply_full += event_content
                    yield event_dict
                    
                elif event_type == "documents":
                    extra_data["documents"] = event_data.get("documents", [])
                    yield event_dict
                    
                elif event_type == "debug":
                    if show_thinking:
                        yield event_dict
                        
                elif event_type == "error":
                    yield event_dict
            
            # æ€§èƒ½ç›‘æ§è®°å½•
            if answer_start is not None:
                answer_duration = time.time() - answer_start
                record_performance('llm_answer', 'ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ', answer_duration,
                                 answer_length=len(ai_reply_full))
            
            llm_total_duration = time.time() - llm_total_start
            record_performance('llm_total', 'LLMå®Œæ•´å¯¹è¯', llm_total_duration,
                             total_thoughts=len(extra_data["thoughts"]),
                             total_actions=len(extra_data["actions"]),
                             total_observations=len(extra_data["observations"]),
                             total_documents=len(extra_data["documents"]),
                             answer_length=len(ai_reply_full))
            
            # 7. ä¿å­˜ AI æ¶ˆæ¯
            if ai_reply_full:
                final_extra_data = {"documents": extra_data["documents"]}
                
                if show_thinking:
                    final_extra_data.update({
                        "thoughts": extra_data["thoughts"],
                        "actions": extra_data["actions"],
                        "observations": extra_data["observations"]
                    })
                
                ai_msg = await message_crud_service.save_ai_message(
                    session_id, 
                    ai_reply_full, 
                    user_id,
                    extra_data=final_extra_data
                )
                
                # 7.1 å¤„ç† thought_chain_id
                thought_chain_id = None
                
                # å¦‚æœæ˜¯ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜çš„ thought_chain_id
                if cached_thought_chain_id:
                    thought_chain_id = cached_thought_chain_id
                    logger.info(f"ä½¿ç”¨ç¼“å­˜çš„ thought_chain_id: {thought_chain_id}")
                else:
                    # ä¿å­˜æ–°çš„æ€ç»´é“¾
                    # æ„å»ºæ–‡æ¡£å¼•ç”¨åˆ—è¡¨
                    documents_used = [
                        {"uuid": doc.get("uuid", ""), "name": doc.get("name", "")}
                        for doc in extra_data["documents"]
                    ]
                    
                    # è·å–é—®ç­”è¯„ä¼°ç»“æœï¼ˆç­‰å¾…å¼‚æ­¥è¯„ä¼°å®Œæˆï¼‰
                    evaluation_id = f"{session_id}:{user_msg.uuid}"
                    should_cache = await qa_evaluator.get_evaluation_result(evaluation_id, timeout=3.0)
                    
                    # åŒæ­¥ä¿å­˜æ€ç»´é“¾ï¼Œè·å– thought_chain_idï¼ˆå§‹ç»ˆä¿å­˜ï¼Œå³ä½¿æ²¡æœ‰ thoughts/actionsï¼‰
                    thought_chain_id = await thought_chain_store.save_chain(
                        session_id=session_id,
                        question=content,  # ä½¿ç”¨åŸå§‹é—®é¢˜ï¼Œä¸æ˜¯å¢å¼ºåçš„å†…å®¹
                        answer=ai_reply_full,
                        thoughts=extra_data["thoughts"],
                        actions=extra_data["actions"],
                        observations=extra_data["observations"],
                        documents_used=documents_used,
                        user_id=user_id,
                        message_id=ai_msg.uuid,
                        should_cache=should_cache
                    )
                    logger.info(f"æ–°æ€ç»´é“¾å·²ä¿å­˜: thought_chain_id={thought_chain_id}")
                
                yield {
                    "event": "ai_message_saved",
                    "data": {
                        "uuid": ai_msg.uuid,
                        "content": ai_msg.content,
                        "thought_chain_id": thought_chain_id  # è¿”å› thought_chain_id
                    }
                }
                
                # 8. æ›´æ–°ä¼šè¯æœ€åæ¶ˆæ¯
                await session_manager.update_last_message(session_id, ai_reply_full)
                
                # 9. æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“
                await summary_service.check_and_save_summary(session_id)
                
                # 10. ç¬¬1è½®å¯¹è¯åè‡ªåŠ¨ç”Ÿæˆä¼šè¯åç§°
                total_messages = await message_crud_service.count_session_messages(session_id)
                
                if total_messages == 2:  # ç”¨æˆ·1æ¡ + AI1æ¡
                    asyncio.create_task(
                        summary_service.auto_generate_session_name(session_id, content, ai_reply_full)
                    )
            
            yield {
                "event": "done",
                "data": {"session_id": session_id}
            }
            
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥ï¼ˆæµå¼ï¼‰: {e}", exc_info=True)
            yield {
                "event": "error",
                "data": {"message": f"å‘é€å¤±è´¥: {str(e)}"}
            }
    
    async def get_session_messages(
        self,
        session_id: str,
        page: int = 1,
        page_size: int = 50
    ) -> Tuple[str, int, Optional[Dict[str, Any]]]:
        """
        è·å–ä¼šè¯çš„æ‰€æœ‰æ¶ˆæ¯
        
        Args:
            session_id: ä¼šè¯ID
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            
        Returns:
            (message, ret, data)
        """
        return await message_crud_service.get_session_messages(session_id, page, page_size)


# åˆ›å»ºå•ä¾‹å®ä¾‹
message_service = MessageService()
