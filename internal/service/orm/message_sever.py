"""
æ¶ˆæ¯ç®¡ç†ä¸šåŠ¡é€»è¾‘ï¼ˆæ¨¡å—åŒ–è®¾è®¡ï¼‰
å‚è€ƒ test_full_rag_qa.py çš„ AI å›ç­”æµç¨‹
é›†æˆ Agent + RAG æ£€ç´¢
"""
from typing import Tuple, Optional, Dict, Any, List, AsyncGenerator
from datetime import datetime
import uuid as uuid_module
import time

from internal.model.message import MessageModel
from internal.model.session import SessionModel
from internal.db.redis import redis_client
from internal.db.milvus import milvus_client
from internal.chat_service.chat_service import ChatService
from internal.rag.rag_service import rag_service
from pkg.model_list import DEEPSEEK_CHAT
from pkg.agent_prompt.prompt_templates import AGENT_RAG_PROMPT
from pkg.agent_prompt.agent_tool import knowledge_search
from log import logger
from pkg.constants.constants import MILVUS_COLLECTION_NAME, SUMMARY_MESSAGE_THRESHOLD
from internal.monitor import record_performance

class MessageService:
    """æ¶ˆæ¯ç®¡ç†æœåŠ¡ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ– RAG æœåŠ¡"""
        if self._initialized:
            return
        
        # åˆå§‹åŒ– RAG æœåŠ¡
        self._init_rag_service()
        self._initialized = True
    
    def _init_rag_service(self):
        """åˆå§‹åŒ– RAG æ£€ç´¢æœåŠ¡"""
        try:
            # è¿æ¥ Milvusï¼ˆå¦‚æœè¿˜æ²¡è¿æ¥ï¼‰
            from pymilvus import connections
            if not connections.has_connection("default"):
                logger.info("è¿æ¥ Milvus...")
                milvus_client.connect()
            
            # è®¾ç½® collection name
            collection_name = MILVUS_COLLECTION_NAME  # é»˜è®¤é›†åˆå
            rag_service.collection_name = collection_name
            
            # åˆå§‹åŒ– RAG æœåŠ¡
            logger.info(f"åˆå§‹åŒ– RAG æ£€ç´¢æœåŠ¡: collection={collection_name}")
            rag_service.initialize()
            
            logger.info("âœ“ RAG æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"RAG æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†åœ¨æ²¡æœ‰ RAG çš„æƒ…å†µä¸‹è¿è¡Œ")
    
    # ==================== ç§æœ‰è¾…åŠ©å‡½æ•°ï¼ˆæ¨¡å—åŒ–ï¼‰====================
    
    async def _create_or_get_session(
        self, 
        session_id: Optional[str], 
        user_id: str, 
        content: str
    ) -> Tuple[str, str]:
        """
        åˆ›å»ºæˆ–è·å–ä¼šè¯
        
        Args:
            session_id: ä¼šè¯IDï¼ˆå¯é€‰ï¼‰
            user_id: ç”¨æˆ·ID
            content: æ¶ˆæ¯å†…å®¹ï¼ˆç”¨äºç”Ÿæˆä¼šè¯åç§°ï¼‰
            
        Returns:
            (session_id, session_name)
        """
        try:
            if session_id:
                # æŸ¥æ‰¾ç°æœ‰ä¼šè¯
                session = await SessionModel.find_one(SessionModel.uuid == session_id)
                if session:
                    logger.info(f"ä½¿ç”¨ç°æœ‰ä¼šè¯: {session_id}")
                    return session.uuid, session.name
                else:
                    logger.warning(f"ä¼šè¯ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°ä¼šè¯: {session_id}")
            
            # åˆ›å»ºæ–°ä¼šè¯
            # ä¼šè¯åç§°ï¼šæ¶ˆæ¯å‰10ä¸ªå­—ç¬¦ï¼Œè¶…è¿‡åˆ™åŠ "..."
            session_name = content[:10] + ("..." if len(content) > 10 else "")
            
            new_session = SessionModel(
                uuid=str(uuid_module.uuid4()),
                user_id=user_id,
                name=session_name,
                last_message=content
            )
            await new_session.insert()
            
            logger.info(f"åˆ›å»ºæ–°ä¼šè¯: {new_session.uuid}, åç§°: {session_name}")
            return new_session.uuid, session_name
            
        except Exception as e:
            logger.error(f"åˆ›å»º/è·å–ä¼šè¯å¤±è´¥: {e}", exc_info=True)
            raise
    
    async def _save_user_message(
        self,
        session_id: str,
        content: str,
        user_id: str,
        send_name: str,
        send_avatar: str,
        file_type: Optional[str] = None,
        file_name: Optional[str] = None,
        file_size: Optional[str] = None,
        file_content: Optional[str] = None
    ) -> MessageModel:
        """
        ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
        
        Args:
            file_content: æ–‡ä»¶åŸå§‹å†…å®¹ï¼ˆä¿å­˜åˆ° extra_dataï¼‰
        
        Returns:
            MessageModel: ä¿å­˜çš„æ¶ˆæ¯å¯¹è±¡
        """
        try:
            # ğŸ”¥ å¦‚æœæœ‰æ–‡ä»¶å†…å®¹ï¼Œä¿å­˜åˆ° extra_data
            extra_data = None
            if file_content:
                extra_data = {
                    "file_content": file_content,
                    "file_type": file_type,
                    "file_name": file_name
                }
                logger.info(f"ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶: {file_name}, å†…å®¹é•¿åº¦: {len(file_content)}")
            
            message = MessageModel(
                uuid=str(uuid_module.uuid4()),
                session_id=session_id,
                content=content,
                send_type=0,  # 0.ç”¨æˆ·
                send_id=user_id,
                send_name=send_name,
                send_avatar=send_avatar,
                receive_id="system",  # AIç³»ç»Ÿ
                file_type=file_type,
                file_name=file_name,
                file_size=file_size,
                extra_data=extra_data,  # ğŸ”¥ ä¿å­˜æ–‡ä»¶å†…å®¹åˆ° extra_data
                status=1,  # 1.å·²å‘é€
                send_at=datetime.now()
            )
            await message.insert()
            
            logger.info(f"ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜: {message.uuid}, session: {session_id}, has_file={file_content is not None}")
            return message
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
            raise
    
    async def _get_session_history(self, session_id: str) -> List[Dict[str, Any]]:
        """
        è·å–ä¼šè¯çš„å†å²æ¶ˆæ¯ï¼ˆæ™ºèƒ½åŠ è½½ï¼‰
        
        ç­–ç•¥ï¼š
        - å¦‚æœå­˜åœ¨ send_type=2ï¼ˆç³»ç»Ÿæ€»ç»“ï¼‰ï¼ŒåªåŠ è½½æœ€åä¸€æ¡æ€»ç»“ + ä¹‹åçš„æ–°æ¶ˆæ¯
        - å¦‚æœä¸å­˜åœ¨æ€»ç»“ï¼ŒåŠ è½½æ‰€æœ‰å†å²æ¶ˆæ¯
        
        Returns:
            List[Dict]: æ ¼å¼åŒ–çš„å†å²æ¶ˆæ¯åˆ—è¡¨ [{"role": "user/assistant/system", "content": "..."}]
        """
        try:
            # 1. æŸ¥æ‰¾æœ€åä¸€æ¡ç³»ç»Ÿæ€»ç»“æ¶ˆæ¯ï¼ˆsend_type=2ï¼‰
            last_summary = await MessageModel.find(
                MessageModel.session_id == session_id,
                MessageModel.send_type == 2
            ).sort(-MessageModel.created_at).limit(1).to_list()
            
            if last_summary:
                # æœ‰æ€»ç»“ï¼šåªåŠ è½½æ€»ç»“ + ä¹‹åçš„æ¶ˆæ¯
                summary_msg = last_summary[0]
                logger.info(f"æ‰¾åˆ°ç³»ç»Ÿæ€»ç»“æ¶ˆæ¯: {summary_msg.uuid}, æ—¶é—´: {summary_msg.created_at}")
                
                # æŸ¥è¯¢æ€»ç»“ä¹‹åçš„æ‰€æœ‰æ¶ˆæ¯
                messages_after_summary = await MessageModel.find(
                    MessageModel.session_id == session_id,
                    MessageModel.created_at > summary_msg.created_at
                ).sort(MessageModel.created_at).to_list()
                
                # æ„å»ºå†å²è®°å½•ï¼šæ€»ç»“ + æ–°æ¶ˆæ¯
                history = []
                
                # æ·»åŠ æ€»ç»“æ¶ˆæ¯ï¼ˆä½œä¸ºç³»ç»Ÿæ¶ˆæ¯ï¼‰
                history.append({
                    "role": "system",
                    "content": f"[å†å²å¯¹è¯æ€»ç»“]\n{summary_msg.content}"
                })
                
                # æ·»åŠ æ€»ç»“ä¹‹åçš„æ–°æ¶ˆæ¯
                for msg in messages_after_summary:
                    if msg.send_type == 0:  # ç”¨æˆ·æ¶ˆæ¯
                        role = "user"
                    elif msg.send_type == 1:  # AIæ¶ˆæ¯
                        role = "assistant"
                    else:  # send_type=2 çš„æ€»ç»“æ¶ˆæ¯ä¸åº”è¯¥å†å‡ºç°åœ¨è¿™é‡Œ
                        continue
                    
                    history.append({
                        "role": role,
                        "content": msg.content
                    })
                
                logger.info(f"è·å–ä¼šè¯å†å²ï¼ˆæ™ºèƒ½åŠ è½½ï¼‰: session={session_id}, æ€»ç»“1æ¡ + æ–°æ¶ˆæ¯{len(messages_after_summary)}æ¡")
                return history
            else:
                # æ²¡æœ‰æ€»ç»“ï¼šåŠ è½½æ‰€æœ‰å†å²æ¶ˆæ¯
                messages = await MessageModel.find(
                    MessageModel.session_id == session_id
                ).sort(MessageModel.created_at).to_list()
                
                history = []
                for msg in messages:
                    if msg.send_type == 0:  # ç”¨æˆ·æ¶ˆæ¯
                        role = "user"
                    elif msg.send_type == 1:  # AIæ¶ˆæ¯
                        role = "assistant"
                    else:  # send_type=2 çš„æ€»ç»“æ¶ˆæ¯ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å­˜åœ¨ï¼Œä½†åšé˜²å¾¡æ€§å¤„ç†ï¼‰
                        continue
                    
                    history.append({
                        "role": role,
                        "content": msg.content
                    })
                
                logger.info(f"è·å–ä¼šè¯å†å²ï¼ˆå…¨é‡åŠ è½½ï¼‰: session={session_id}, å…± {len(history)} æ¡æ¶ˆæ¯")
                return history
            
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯å†å²å¤±è´¥: {e}", exc_info=True)
            return []
    
    async def _generate_ai_reply(
        self,
        session_id: str,
        user_id: str,
        user_message: str,
        history: List[Dict[str, Any]],
        stream: bool = False
    ) -> str:
        """
        ç”Ÿæˆ AI å›å¤ï¼ˆä½¿ç”¨ ChatService + Agent + RAGï¼‰
        å‚è€ƒ test_full_rag_qa.py çš„å®ç°
        
        Args:
            session_id: ä¼šè¯ID
            user_id: ç”¨æˆ·ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            history: å†å²è®°å½•
            stream: æ˜¯å¦æµå¼è¿”å›
            
        Returns:
            str: AI å›å¤å†…å®¹ï¼ˆéæµå¼ï¼‰æˆ–ç©ºå­—ç¬¦ä¸²ï¼ˆæµå¼ï¼Œå†…å®¹é€šè¿‡ yield è¿”å›ï¼‰
        """
        try:
            logger.info(f"å¼€å§‹ç”Ÿæˆ AI å›å¤ï¼ˆAgent + RAGï¼‰: session={session_id}, stream={stream}")
            
            # åˆå§‹åŒ– ChatService
            # æ³¨æ„ï¼šauto_summary=Falseï¼Œå› ä¸ºæˆ‘ä»¬åœ¨æ•°æ®åº“å±‚é¢å®ç°äº†æŒä¹…åŒ–æ€»ç»“ï¼ˆsend_type=2ï¼‰
            chat_service = ChatService(
                session_id=session_id,
                user_id=user_id,
                model_name=DEEPSEEK_CHAT.name,
                model_type=DEEPSEEK_CHAT.model_type,
                system_prompt=AGENT_RAG_PROMPT,  # ä½¿ç”¨ Agent RAG æç¤ºè¯
                tools=[knowledge_search],  # ä¼ é€’ RAG å·¥å…·
                auto_summary=False,  # å…³é—­åº•å±‚è‡ªåŠ¨æ€»ç»“ï¼Œé¿å…ä¸æ•°æ®åº“æ€»ç»“é‡å¤
                max_history_count=10  # ä¿æŒæœ€è¿‘10æ¡å†å²
            )
            
            # ğŸ”¥ åŠ è½½å†å²è®°å½•æ—¶æ·»åŠ ä¸Šä¸‹æ–‡åˆ†éš”ï¼ˆæ’é™¤æœ€åä¸€æ¡ï¼Œå› ä¸ºæ˜¯å½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼‰
            if len(history) > 1:
                # æ·»åŠ å†å²å¯¹è¯æ ‡è®°
                chat_service.add_to_history("system", "--- ä»¥ä¸‹æ˜¯å†å²å¯¹è¯è®°å½•---")
                for msg in history[:-1]:
                    chat_service.add_to_history(msg['role'], msg['content'])
                # æ·»åŠ å½“å‰é—®é¢˜æ ‡è®°
                chat_service.add_to_history("system", "--- ä»¥ä¸Šæ˜¯å†å²å¯¹è¯ï¼Œä»¥ä¸‹æ˜¯ç”¨æˆ·å½“å‰çš„æ–°é—®é¢˜ ---")
                logger.info(f"å·²åŠ è½½ {len(history)-1} æ¡å†å²è®°å½•")
            
            # å‡†å¤‡ Agent å·¥å…·
            agent_tools = {
                "knowledge_search": knowledge_search
            }
            
            # è°ƒç”¨ AI ç”Ÿæˆå›å¤ï¼ˆä¸ test_full_rag_qa.py ä¸€è‡´ï¼‰
            logger.info(f"è°ƒç”¨ ChatService.chat() ç”Ÿæˆå›å¤...")
            ai_reply = chat_service.chat(
                user_message=user_message,
                use_agent=True,  # å¯ç”¨ Agent
                agent_tools=agent_tools,  # ä¼ é€’å·¥å…·
                save_only_answer=True,  # åªä¿å­˜é—®ç­”ï¼Œä¸ä¿å­˜æ€è€ƒè¿‡ç¨‹
                max_iterations=5,  # æœ€å¤§è¿­ä»£æ¬¡æ•°
                verbose=True,  # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
                stream=stream  # æµå¼æˆ–éæµå¼
            )
            
            logger.info(f"AI å›å¤ç”ŸæˆæˆåŠŸ: {len(ai_reply) if isinstance(ai_reply, str) else 'streaming'}")
            return ai_reply
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆ AI å›å¤å¤±è´¥: {e}", exc_info=True)
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    async def _generate_ai_reply_stream(
        self,
        session_id: str,
        user_id: str,
        user_message: str,
        history: List[Dict[str, Any]]
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """ç”Ÿæˆ AI å›å¤ï¼ˆçœŸæ­£çš„æµå¼ï¼‰- ä½¿ç”¨å›è°ƒæœºåˆ¶"""
        import asyncio
        import queue
        
        try:
            from internal.chat_service.chat_service import ChatService
            from internal.agent.react_agent import ReActAgent
            from internal.model.user_info import UserInfoModel
            
            # ğŸ”¥ è·å–ç”¨æˆ·æƒé™ä¿¡æ¯
            user_info = await UserInfoModel.find_one(UserInfoModel.uuid == user_id)
            user_permission = user_info.is_admin if user_info else 0
            logger.info(f"ç”¨æˆ·æƒé™: user_id={user_id}, is_admin={user_permission}")
            
            # ğŸ”¥ åˆ›å»ºç»‘å®šäº†ç”¨æˆ·æƒé™çš„ knowledge_search å·¥å…·ï¼ˆä½¿ç”¨åŒ…è£…å‡½æ•°è€Œä¸æ˜¯ partialï¼‰
            def knowledge_search_with_permission(query: str, top_k: int = 5, use_reranker: bool = True):
                """çŸ¥è¯†åº“æœç´¢å·¥å…·ï¼ˆå·²ç»‘å®šç”¨æˆ·æƒé™ï¼‰"""
                return knowledge_search(query=query, top_k=top_k, use_reranker=use_reranker, user_permission=user_permission)
            
            # æ³¨æ„ï¼šauto_summary=Falseï¼Œå› ä¸ºæˆ‘ä»¬åœ¨æ•°æ®åº“å±‚é¢å®ç°äº†æŒä¹…åŒ–æ€»ç»“ï¼ˆsend_type=2ï¼‰
            chat_service = ChatService(
                session_id=session_id,
                user_id=user_id,
                model_name=DEEPSEEK_CHAT.name,
                model_type=DEEPSEEK_CHAT.model_type,
                system_prompt=AGENT_RAG_PROMPT,
                tools=[knowledge_search_with_permission],  # ğŸ”¥ ä½¿ç”¨ç»‘å®šäº†æƒé™çš„å·¥å…·
                auto_summary=False,  # å…³é—­åº•å±‚è‡ªåŠ¨æ€»ç»“ï¼Œé¿å…ä¸æ•°æ®åº“æ€»ç»“é‡å¤
                max_history_count=10
            )
            
            # ğŸ”¥ åŠ è½½å†å²è®°å½•æ—¶æ·»åŠ ä¸Šä¸‹æ–‡åˆ†éš”
            if len(history) > 1:
                # æ·»åŠ å†å²å¯¹è¯æ ‡è®°
                chat_service.add_to_history("system", "--- ä»¥ä¸‹æ˜¯å†å²å¯¹è¯è®°å½•---")
                for msg in history[:-1]:
                    chat_service.add_to_history(msg['role'], msg['content'])
                # æ·»åŠ å½“å‰é—®é¢˜æ ‡è®°
                chat_service.add_to_history("system", "--- ä»¥ä¸Šæ˜¯å†å²å¯¹è¯ï¼Œä»¥ä¸‹æ˜¯ç”¨æˆ·å½“å‰çš„æ–°é—®é¢˜ ---")
            
            # åˆ›å»ºäº‹ä»¶é˜Ÿåˆ—
            event_queue = queue.Queue()
            
            # ç”¨äºæ”¶é›†æ–‡æ¡£ä¿¡æ¯
            retrieved_documents = []
            
            # å®šä¹‰å›è°ƒå‡½æ•°
            def callback(event_type, content):
                nonlocal retrieved_documents
                
                # å¦‚æœæ˜¯å·¥å…·ç»“æœï¼Œæ”¶é›†æ–‡æ¡£ä¿¡æ¯
                if event_type == "tool_result" and isinstance(content, dict):
                    documents = content.get("documents", [])
                    logger.info(f"ğŸ” å·¥å…·è¿”å›æ–‡æ¡£æ•°é‡: {len(documents)}")
                    if documents:
                        # å»é‡åˆå¹¶æ–‡æ¡£
                        existing_uuids = {doc["uuid"] for doc in retrieved_documents}
                        for doc in documents:
                            if doc["uuid"] not in existing_uuids:
                                retrieved_documents.append(doc)
                                existing_uuids.add(doc["uuid"])
                                logger.info(f"ğŸ“„ æ·»åŠ æ–‡æ¡£: {doc['name']} ({doc['uuid']})")
                
                event_queue.put((event_type, content))
            
            # åˆ›å»º Agent å¹¶ä¼ å…¥å›è°ƒï¼ˆä½¿ç”¨ç»‘å®šäº†æƒé™çš„å·¥å…·ï¼‰
            agent = ReActAgent(
                llm_service=chat_service.llm_service,
                tools={"knowledge_search": knowledge_search_with_permission},  # ğŸ”¥ ä½¿ç”¨ç»‘å®šäº†æƒé™çš„å·¥å…·
                max_iterations=5,
                verbose=False,
                callback=callback
            )
            
            # åœ¨åå°çº¿ç¨‹è¿è¡Œ Agent
            async def run_agent():
                return await asyncio.to_thread(lambda: agent.run(user_message, stream=True))
            
            # å¯åŠ¨ Agent ä»»åŠ¡
            agent_task = asyncio.create_task(run_agent())
            
            # å®æ—¶è¯»å–é˜Ÿåˆ—å¹¶yieldäº‹ä»¶
            current_line = ""
            in_answer = False
            
            while not agent_task.done() or not event_queue.empty():
                try:
                    event_type, content = event_queue.get_nowait()
                    
                    # ğŸ”¥ å¤„ç† tool_result äº‹ä»¶ï¼ˆå·²åœ¨ callback ä¸­æ”¶é›†æ–‡æ¡£ï¼Œè¿™é‡Œåªéœ€è¦è·³è¿‡ï¼‰
                    if event_type == "tool_result":
                        logger.debug(f"æ”¶åˆ°å·¥å…·ç»“æœï¼Œå·²æ”¶é›†æ–‡æ¡£ä¿¡æ¯")
                        continue
                    
                    # ğŸ”¥ å¤„ç† Observation äº‹ä»¶
                    elif event_type == "observation":
                        yield {
                            "event": "observation",
                            "data": {"content": content}
                        }
                    
                    elif event_type == "llm_chunk":
                        current_line += content
                        
                        # æ£€æµ‹äº‹ä»¶ç±»å‹
                        if '\n' in current_line:
                            lines = current_line.split('\n')
                            for line in lines[:-1]:
                                line = line.strip()
                                if line.startswith('Thought:'):
                                    yield {
                                        "event": "thought",
                                        "data": {"content": line.replace('Thought:', '').strip()}
                                    }
                                elif line.startswith('Action:'):
                                    yield {
                                        "event": "action",
                                        "data": {"content": line.replace('Action:', '').strip()}
                                    }
                                elif line.startswith('Answer:'):
                                    in_answer = True
                                    answer_start = line.replace('Answer:', '').strip()
                                    if answer_start:
                                        yield {
                                            "event": "answer_chunk",
                                            "data": {"content": answer_start}
                                        }
                            current_line = lines[-1]
                        
                        # ğŸ”¥ å®æ—¶æ£€æµ‹ Answer: å¼€å¤´ï¼ˆå³ä½¿æ²¡æœ‰æ¢è¡Œç¬¦ï¼‰
                        if not in_answer and 'Answer:' in current_line:
                            in_answer = True
                            # æå– Answer: åé¢çš„å†…å®¹
                            answer_part = current_line.split('Answer:', 1)[1]
                            if answer_part.strip():
                                yield {
                                    "event": "answer_chunk",
                                    "data": {"content": answer_part}
                                }
                            current_line = ""  # æ¸…ç©ºå·²å¤„ç†çš„å†…å®¹
                        # å¦‚æœåœ¨ Answer éƒ¨åˆ†ï¼Œå®æ—¶è¾“å‡º
                        elif in_answer and content not in ['\n', '\r\n']:
                            yield {
                                "event": "answer_chunk",
                                "data": {"content": content}
                            }
                
                except queue.Empty:
                    await asyncio.sleep(0.01)  # ç­‰å¾…æ–°äº‹ä»¶
            
            # ğŸ”¥ å¾ªç¯ç»“æŸåï¼Œæ£€æŸ¥æ˜¯å¦æœ‰é—ç•™çš„ Answer å†…å®¹
            if current_line.strip() and not in_answer:
                if 'Answer:' in current_line:
                    answer_part = current_line.split('Answer:', 1)[1].strip()
                    if answer_part:
                        yield {
                            "event": "answer_chunk",
                            "data": {"content": answer_part}
                        }
            
            # ç­‰å¾… Agent å®Œæˆ
            result = await agent_task
            logger.info(f"Agent å®Œæˆ: {len(result)} å­—ç¬¦")
            
            # ğŸ”¥ å‘é€æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¿¡æ¯
            logger.info(f"ğŸ“š å‡†å¤‡å‘é€æ–‡æ¡£åˆ—è¡¨ï¼Œå½“å‰æ”¶é›†åˆ° {len(retrieved_documents)} ä¸ªæ–‡æ¡£")
            if retrieved_documents:
                logger.info(f"âœ… å‘é€æ£€ç´¢æ–‡æ¡£ä¿¡æ¯: {retrieved_documents}")
                yield {
                    "event": "documents",
                    "data": {"documents": retrieved_documents}
                }
            else:
                logger.warning("âš ï¸ æ²¡æœ‰æ”¶é›†åˆ°æ–‡æ¡£ä¿¡æ¯")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆ AI å›å¤å¤±è´¥: {e}", exc_info=True)
            yield {
                "event": "error",
                "data": {"content": str(e)}
            }
    
    async def _save_ai_message(
        self,
        session_id: str,
        content: str,
        receive_id: str,
        extra_data: Optional[Dict[str, Any]] = None
    ) -> MessageModel:
        """
        ä¿å­˜ AI æ¶ˆæ¯åˆ°æ•°æ®åº“
        
        Args:
            extra_data: é¢å¤–æ•°æ®ï¼ˆæ€è€ƒè¿‡ç¨‹ã€æ–‡æ¡£ç­‰ï¼‰
        
        Returns:
            MessageModel: ä¿å­˜çš„æ¶ˆæ¯å¯¹è±¡
        """
        try:
            logger.debug(f"_save_ai_messageæ”¶åˆ°extra_data: type={type(extra_data)}, value={extra_data}")
            
            message = MessageModel(
                uuid=str(uuid_module.uuid4()),
                session_id=session_id,
                content=content,
                send_type=1,  # 1.AI
                send_id="system",
                send_name="AIåŠ©æ‰‹",
                send_avatar="",
                receive_id=receive_id,
                extra_data=extra_data,  # ğŸ”¥ å­˜å‚¨é¢å¤–æ•°æ®
                status=1,  # 1.å·²å‘é€
                send_at=datetime.now()
            )
            
            logger.debug(f"MessageModelåˆ›å»ºåextra_data: {message.extra_data}")
            
            await message.insert()
            
            logger.info(f"AI æ¶ˆæ¯å·²ä¿å­˜: {message.uuid}, session: {session_id}, extra_dataæœ‰{len(extra_data.get('documents', []) if extra_data else [])}ä¸ªæ–‡æ¡£")
            
            # åŒæ—¶ä¿å­˜åˆ° Redisï¼ˆç¼“å­˜æœ€åä¸€æ¡ AI æ¶ˆæ¯ï¼‰
            try:
                key = f"session:{session_id}:last_ai_message"
                redis_client.set(key, content, ex=3600)  # 1å°æ—¶è¿‡æœŸ
                logger.info(f"AI æ¶ˆæ¯å·²ç¼“å­˜åˆ° Redis: {key}")
            except Exception as e:
                logger.warning(f"ç¼“å­˜ AI æ¶ˆæ¯åˆ° Redis å¤±è´¥: {e}")
            
            return message
            
        except Exception as e:
            logger.error(f"ä¿å­˜ AI æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
            raise
    
    async def _update_session_last_message(self, session_id: str, message: str):
        """
        æ›´æ–°ä¼šè¯çš„æœ€åä¸€æ¡æ¶ˆæ¯
        """
        try:
            session = await SessionModel.find_one(SessionModel.uuid == session_id)
            if session:
                session.last_message = message
                session.update_at = datetime.now()
                await session.save()
                logger.info(f"ä¼šè¯æœ€åæ¶ˆæ¯å·²æ›´æ–°: {session_id}")
            else:
                logger.warning(f"ä¼šè¯ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°: {session_id}")
                
        except Exception as e:
            logger.error(f"æ›´æ–°ä¼šè¯æœ€åæ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
    
    async def _check_and_save_summary(self, session_id: str, threshold: int = None):
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“å¹¶ä¿å­˜åˆ°æ•°æ®åº“
        
        ç­–ç•¥ï¼š
        - å¦‚æœæœ‰å†å²æ€»ç»“ï¼Œç»Ÿè®¡ä¹‹åçš„æ–°æ¶ˆæ¯æ•°
        - å¦‚æœæ–°æ¶ˆæ¯è¶…è¿‡é˜ˆå€¼ï¼Œåˆ©ç”¨åº•å±‚ LLMService ç”Ÿæˆæ€»ç»“å¹¶ä¿å­˜
        - å¦‚æœæ²¡æœ‰æ€»ç»“ä¸”æ€»æ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼ï¼Œç”Ÿæˆç¬¬ä¸€æ¬¡æ€»ç»“
        
        Args:
            session_id: ä¼šè¯ID
            threshold: è§¦å‘æ€»ç»“çš„æ¶ˆæ¯æ•°é‡é˜ˆå€¼ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡è¯»å– SUMMARY_MESSAGE_THRESHOLDï¼‰
        """
        # ä½¿ç”¨å…¨å±€é…ç½®çš„é˜ˆå€¼
        if threshold is None:
            threshold = SUMMARY_MESSAGE_THRESHOLD
        
        logger.info(f"ğŸ” æ£€æŸ¥ä¼šè¯æ˜¯å¦éœ€è¦æ€»ç»“: session={session_id}, é˜ˆå€¼={threshold}")
        
        try:
            # æŸ¥æ‰¾æœ€åä¸€æ¡ç³»ç»Ÿæ€»ç»“
            last_summary = await MessageModel.find(
                MessageModel.session_id == session_id,
                MessageModel.send_type == 2
            ).sort(-MessageModel.created_at).limit(1).to_list()
            
            # ç»Ÿè®¡éœ€è¦æ€»ç»“çš„æ¶ˆæ¯
            if last_summary:
                # æœ‰æ€»ç»“ï¼šç»Ÿè®¡ä¹‹åçš„æ–°æ¶ˆæ¯
                new_messages = await MessageModel.find(
                    MessageModel.session_id == session_id,
                    MessageModel.created_at > last_summary[0].created_at,
                    MessageModel.send_type != 2
                ).sort(MessageModel.created_at).to_list()
                
                messages_to_summarize = new_messages
                base_summary = f"[å†å²å¯¹è¯æ€»ç»“]\n{last_summary[0].content}\n\n[æ–°å¢å¯¹è¯]\n"
                logger.info(f"ğŸ“Š æ‰¾åˆ°å†å²æ€»ç»“ï¼Œæ–°æ¶ˆæ¯æ•°: {len(messages_to_summarize)}")
            else:
                # æ²¡æœ‰æ€»ç»“ï¼šç»Ÿè®¡æ‰€æœ‰æ¶ˆæ¯
                messages_to_summarize = await MessageModel.find(
                    MessageModel.session_id == session_id,
                    MessageModel.send_type != 2
                ).sort(MessageModel.created_at).to_list()
                
                base_summary = "[å¯¹è¯è®°å½•]\n"
                logger.info(f"ğŸ“Š æœªæ‰¾åˆ°å†å²æ€»ç»“ï¼Œæ€»æ¶ˆæ¯æ•°: {len(messages_to_summarize)}")
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            if len(messages_to_summarize) < threshold:
                logger.info(f"â¸ï¸  æ¶ˆæ¯æ•°{len(messages_to_summarize)}æ¡ï¼Œæœªè¾¾åˆ°é˜ˆå€¼{threshold}ï¼Œæš‚ä¸æ€»ç»“")
                return
            
            logger.info(f"âœ… æ¶ˆæ¯æ•°{len(messages_to_summarize)}æ¡ï¼Œè¶…è¿‡é˜ˆå€¼{threshold}ï¼Œå¼€å§‹ç”Ÿæˆæ€»ç»“...")
            
            # æ„å»ºå¯¹è¯æ–‡æœ¬ï¼ˆåˆ©ç”¨å·²æœ‰æ¶ˆæ¯æ•°æ®ï¼‰
            dialog_text = base_summary
            for msg in messages_to_summarize:
                role = "ç”¨æˆ·" if msg.send_type == 0 else "AIåŠ©æ‰‹"
                dialog_text += f"{role}ï¼š{msg.content}\n"
            
            logger.info(f"ğŸ“ å¯¹è¯æ–‡æœ¬æ„å»ºå®Œæˆï¼Œå‡†å¤‡è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“...")
            
            # ğŸ”¥ åˆ©ç”¨åº•å±‚ LLMService çš„æ€»ç»“èƒ½åŠ›ï¼ˆé€šè¿‡ SUMMARY_PROMPTï¼‰
            from internal.llm.llm_service import LLMService
            from pkg.agent_prompt.prompt_templates import SUMMARY_PROMPT
            
            llm_service = LLMService(
                model_name=DEEPSEEK_CHAT.name,
                model_type=DEEPSEEK_CHAT.model_type,
                auto_summary=False  # è¿™é‡Œä¸éœ€è¦è‡ªåŠ¨æ€»ç»“
            )
            
            summary_messages = [
                {"role": "system", "content": SUMMARY_PROMPT},
                {"role": "user", "content": f"è¯·æ€»ç»“ä»¥ä¸‹å¯¹è¯ï¼š\n\n{dialog_text}"}
            ]
            
            # ç”Ÿæˆæ€»ç»“
            logger.info(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆæ€»ç»“...")
            summary = llm_service.chat(messages=summary_messages, stream=False, use_history=False)
            logger.info(f"âœ¨ LLM æ€»ç»“ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(summary)} å­—ç¬¦")
            
            # ä¿å­˜æ€»ç»“åˆ°æ•°æ®åº“
            message = MessageModel(
                uuid=str(uuid_module.uuid4()),
                session_id=session_id,
                content=summary.strip(),
                send_type=2,  # 2.ç³»ç»Ÿæ€»ç»“
                send_id="system",
                send_name="ç³»ç»Ÿ",
                send_avatar="",
                receive_id="system",
                status=1,
                send_at=datetime.now()
            )
            
            await message.insert()
            logger.info(f"ğŸ’¾ æ€»ç»“å·²ä¿å­˜åˆ°æ•°æ®åº“: message_id={message.uuid}, send_type=2")
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥å¹¶ä¿å­˜æ€»ç»“å¤±è´¥: {e}", exc_info=True)
    
    async def _auto_generate_session_name(
        self, 
        session_id: str, 
        user_question: str, 
        ai_answer: str
    ):
        """
        è‡ªåŠ¨ç”Ÿæˆä¼šè¯åç§°ï¼ˆç¬¬1è½®å¯¹è¯åè§¦å‘ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            user_question: ç”¨æˆ·é—®é¢˜
            ai_answer: AIå›ç­”
        """
        try:
            logger.info(f"å¼€å§‹è‡ªåŠ¨ç”Ÿæˆä¼šè¯åç§°: session={session_id}")
            
            # ä½¿ç”¨ LLMService ç”Ÿæˆç®€çŸ­æ ‡é¢˜
            from internal.llm.llm_service import LLMService
            
            llm_service = LLMService(
                model_name=DEEPSEEK_CHAT.name,
                model_type=DEEPSEEK_CHAT.model_type,
                auto_summary=False
            )
            
            # æç¤ºè¯ï¼šè¦æ±‚ç”Ÿæˆ8-15å­—çš„ç®€çŸ­æ ‡é¢˜
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯ï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„ä¼šè¯æ ‡é¢˜ï¼ˆ8-15ä¸ªå­—ï¼‰ã€‚
åªè¿”å›æ ‡é¢˜æœ¬èº«ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{user_question}
AIå›ç­”ï¼š{ai_answer[:200]}...

æ ‡é¢˜ï¼š"""
            
            # è°ƒç”¨ LLM ç”Ÿæˆæ ‡é¢˜
            response = llm_service.chat(user_message=prompt, stream=False, use_history=False)
            title = response.strip().strip('"').strip("'")
            
            # é™åˆ¶é•¿åº¦
            if len(title) > 20:
                title = title[:20]
            
            logger.info(f"ç”Ÿæˆçš„ä¼šè¯æ ‡é¢˜: {title}")
            
            # ä½¿ç”¨ UpdateSessionRequest æ›´æ–°ä¼šè¯åç§°
            from internal.dto.request import UpdateSessionRequest
            from internal.service.orm.session_sever import session_service
            
            req = UpdateSessionRequest(uuid=session_id, name=title)
            message, ret = await session_service.update_session(session_id, req)
            
            if ret == 0:
                logger.info(f"ä¼šè¯åç§°è‡ªåŠ¨æ›´æ–°æˆåŠŸ: {session_id} -> {title}")
            else:
                logger.warning(f"ä¼šè¯åç§°è‡ªåŠ¨æ›´æ–°å¤±è´¥: {message}")
                
        except Exception as e:
            logger.error(f"è‡ªåŠ¨ç”Ÿæˆä¼šè¯åç§°å¤±è´¥: {e}", exc_info=True)
    
    # ==================== å…¬å…±æ¥å£ ====================
    
    async def send_message_stream(
        self,
        content: str,
        user_id: str,
        send_name: str,
        send_avatar: str,
        session_id: Optional[str] = None,
        file_type: Optional[str] = None,
        file_name: Optional[str] = None,
        file_size: Optional[str] = None,
        file_content: Optional[str] = None,
        show_thinking: bool = False,
        enhanced_content: Optional[str] = None
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """
        å‘é€æ¶ˆæ¯ï¼ˆç»Ÿä¸€æµå¼è¿”å›ï¼Œæ”¯æŒæ–‡ä»¶å†…å®¹ï¼‰
        
        Args:
            content: ç”¨æˆ·çš„åŸå§‹é—®é¢˜ï¼ˆä¿å­˜åˆ°æ•°æ®åº“ï¼‰
            file_content: æ–‡ä»¶åŸå§‹å†…å®¹ï¼ˆç”¨äºä¿å­˜åˆ° extra_dataï¼‰
            enhanced_content: å¢å¼ºå†…å®¹ï¼ˆåŒ…å«æ–‡ä»¶å†…å®¹ï¼Œå‘é€ç»™ AIï¼‰
            show_thinking: æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼ˆThought/Action/Observationï¼‰
        
        Yields:
            Dict: åŒ…å«äº‹ä»¶ç±»å‹å’Œæ•°æ®çš„å­—å…¸
                - event: äº‹ä»¶ç±»å‹
                - data: äº‹ä»¶æ•°æ®
        
        äº‹ä»¶ç±»å‹ï¼š
            - session_created: ä¼šè¯åˆ›å»º
            - user_message_saved: ç”¨æˆ·æ¶ˆæ¯ä¿å­˜å®Œæˆ
            - thought: Agent æ€è€ƒï¼ˆä»…å½“ show_thinking=Trueï¼‰
            - action: Agent åŠ¨ä½œï¼ˆä»…å½“ show_thinking=Trueï¼‰
            - observation: è§‚å¯Ÿç»“æœï¼ˆä»…å½“ show_thinking=Trueï¼‰
            - answer_chunk: æœ€ç»ˆç­”æ¡ˆç‰‡æ®µ
            - ai_message_saved: AI æ¶ˆæ¯ä¿å­˜å®Œæˆ
            - done: å®Œæˆ
            - error: é”™è¯¯
        """
        try:
            logger.info(f"æ”¶åˆ°æ¶ˆæ¯å‘é€è¯·æ±‚ï¼ˆæµå¼ï¼‰: user={user_id}, session={session_id}, show_thinking={show_thinking}")
            
            # 1. åˆ›å»ºæˆ–è·å–ä¼šè¯
            logger.debug(f"å¼€å§‹åˆ›å»ºæˆ–è·å–ä¼šè¯...")
            session_id, session_name = await self._create_or_get_session(
                session_id, user_id, content
            )
            logger.debug(f"ä¼šè¯å·²å‡†å¤‡: session_id={session_id}, session_name={session_name}")
            
            yield {
                "event": "session_created",
                "data": {
                    "session_id": session_id,
                    "session_name": session_name
                }
            }
            
            # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«æ–‡ä»¶å†…å®¹ï¼‰
            user_msg = await self._save_user_message(
                session_id, content, user_id, send_name, send_avatar,
                file_type, file_name, file_size, file_content
            )
            
            yield {
                "event": "user_message_saved",
                "data": {
                    "uuid": user_msg.uuid,
                    "content": user_msg.content
                }
            }
            
            # 3. è·å–ä¼šè¯å†å²
            history = await self._get_session_history(session_id)
            
            # 4. æµå¼ç”Ÿæˆ AI å›å¤ï¼ˆæ”¶é›†é¢å¤–æ•°æ®ï¼‰
            ai_reply_full = ""
            extra_data = {
                "thoughts": [],
                "actions": [],
                "observations": [],
                "documents": []
            }
            
            # â±ï¸ æ€§èƒ½ç›‘æ§ï¼šè®°å½•å„é˜¶æ®µæ—¶é—´
            llm_total_start = time.time()
            current_thought_start = None
            current_action_start = None
            answer_start = None
            
            # ğŸ”¥ å¦‚æœæœ‰æ–‡ä»¶ä¸Šä¼ ï¼Œä½¿ç”¨ enhanced_contentï¼ˆåŒ…å«æ–‡ä»¶å†…å®¹ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨åŸå§‹ content
            ai_input_content = enhanced_content if enhanced_content else content
            logger.info(f"å‘é€ç»™ AI çš„å†…å®¹é•¿åº¦: {len(ai_input_content)}, åŸå§‹é—®é¢˜é•¿åº¦: {len(content)}")
            
            async for event_dict in self._generate_ai_reply_stream(session_id, user_id, ai_input_content, history):
                event_type = event_dict.get("event", "message")
                event_data = event_dict.get("data", {})
                event_content = event_data.get("content", "")
                
                # æ ¹æ® show_thinking å‚æ•°å†³å®šæ˜¯å¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼ŒåŒæ—¶æ”¶é›†åˆ° extra_data
                if event_type == "thought":
                    # â±ï¸ è®°å½• thought å¼€å§‹æ—¶é—´
                    if current_thought_start is None:
                        current_thought_start = time.time()
                    
                    extra_data["thoughts"].append(event_content)
                    if show_thinking:  # åªæœ‰å¯ç”¨æ—¶æ‰è¾“å‡º
                        yield event_dict
                        
                elif event_type == "action":
                    # â±ï¸ thought ç»“æŸï¼Œè®°å½•æ—¶é—´
                    if current_thought_start is not None:
                        think_duration = time.time() - current_thought_start
                        record_performance('llm_think', f'æ€è€ƒæ­¥éª¤{len(extra_data["thoughts"])}', think_duration, 
                                         thought_content=extra_data["thoughts"][-1][:100] if extra_data["thoughts"] else "")
                        current_thought_start = None
                    
                    # â±ï¸ è®°å½• action å¼€å§‹æ—¶é—´
                    current_action_start = time.time()
                    
                    extra_data["actions"].append(event_content)
                    if show_thinking:  # åªæœ‰å¯ç”¨æ—¶æ‰è¾“å‡º
                        yield event_dict
                        
                elif event_type == "observation":
                    # â±ï¸ action ç»“æŸï¼ˆåŒ…å«å·¥å…·æ‰§è¡Œï¼‰ï¼Œè®°å½•æ—¶é—´
                    if current_action_start is not None:
                        action_duration = time.time() - current_action_start
                        record_performance('llm_action', f'åŠ¨ä½œæ­¥éª¤{len(extra_data["actions"])}', action_duration,
                                         action_content=extra_data["actions"][-1][:100] if extra_data["actions"] else "")
                        current_action_start = None
                    
                    extra_data["observations"].append(event_content)
                    if show_thinking:  # åªæœ‰å¯ç”¨æ—¶æ‰è¾“å‡º
                        yield event_dict
                        
                elif event_type == "answer_chunk":
                    # â±ï¸ å¼€å§‹ç”Ÿæˆç­”æ¡ˆï¼Œè®°å½•å¼€å§‹æ—¶é—´
                    if answer_start is None:
                        answer_start = time.time()
                    
                    ai_reply_full += event_content
                    yield event_dict
                    
                elif event_type == "documents":
                    # ğŸ”¥ æ”¶é›†æ–‡æ¡£ä¿¡æ¯åˆ° extra_dataï¼ˆå§‹ç»ˆæ”¶é›†ï¼‰
                    extra_data["documents"] = event_data.get("documents", [])
                    # ä¼ é€’æ–‡æ¡£ä¿¡æ¯ç»™å‰ç«¯ï¼ˆå§‹ç»ˆå‘é€ï¼‰
                    yield event_dict
                elif event_type == "debug":
                    if show_thinking:  # åªæœ‰å¯ç”¨æ—¶æ‰è¾“å‡º
                        yield event_dict
                elif event_type == "error":
                    yield event_dict
            
            # â±ï¸ ç­”æ¡ˆç”Ÿæˆç»“æŸï¼Œè®°å½•æ—¶é—´
            if answer_start is not None:
                answer_duration = time.time() - answer_start
                record_performance('llm_answer', 'ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ', answer_duration,
                                 answer_length=len(ai_reply_full))
            
            # â±ï¸ LLM æ€»æ—¶é—´
            llm_total_duration = time.time() - llm_total_start
            record_performance('llm_total', 'LLMå®Œæ•´å¯¹è¯', llm_total_duration,
                             total_thoughts=len(extra_data["thoughts"]),
                             total_actions=len(extra_data["actions"]),
                             total_observations=len(extra_data["observations"]),
                             total_documents=len(extra_data["documents"]),
                             answer_length=len(ai_reply_full))
            
            # 5. ä¿å­˜ AI æ¶ˆæ¯ï¼ˆåŒ…å« extra_dataï¼‰
            if ai_reply_full:
                # ğŸ”¥ æ ¹æ® show_thinking å†³å®šä¿å­˜å“ªäº›é¢å¤–æ•°æ®
                final_extra_data = {"documents": extra_data["documents"]}
                
                if show_thinking:
                    # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼šä¿å­˜æ‰€æœ‰æ•°æ®
                    final_extra_data.update({
                        "thoughts": extra_data["thoughts"],
                        "actions": extra_data["actions"],
                        "observations": extra_data["observations"]
                    })
                
                logger.debug(f"å‡†å¤‡ä¿å­˜extra_data: {final_extra_data}")
                logger.debug(f"extra_dataç±»å‹: {type(final_extra_data)}, documentsæ•°é‡: {len(final_extra_data.get('documents', []))}")
                
                ai_msg = await self._save_ai_message(
                    session_id, 
                    ai_reply_full, 
                    user_id,
                    extra_data=final_extra_data
                )
                
                yield {
                    "event": "ai_message_saved",
                    "data": {
                        "uuid": ai_msg.uuid,
                        "content": ai_msg.content
                    }
                }
                
                # 6. æ›´æ–°ä¼šè¯æœ€åæ¶ˆæ¯
                await self._update_session_last_message(session_id, ai_reply_full)
                
                # 7. ğŸ”¥ æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ€»ç»“å¹¶ä¿å­˜åˆ°æ•°æ®åº“
                await self._check_and_save_summary(session_id)
                
                # 8. ğŸ”¥ ç¬¬1è½®å¯¹è¯åè‡ªåŠ¨ç”Ÿæˆä¼šè¯åç§°
                total_messages = await MessageModel.find(
                    MessageModel.session_id == session_id,
                    MessageModel.send_type != 2  # æ’é™¤æ€»ç»“æ¶ˆæ¯
                ).count()
                
                if total_messages == 2:  # ç”¨æˆ·1æ¡ + AI1æ¡
                    logger.info(f"æ£€æµ‹åˆ°ç¬¬1è½®å¯¹è¯å®Œæˆï¼Œè§¦å‘è‡ªåŠ¨ç”Ÿæˆä¼šè¯åç§°: session={session_id}")
                    # å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡æµå¼è¿”å›
                    import asyncio
                    asyncio.create_task(
                        self._auto_generate_session_name(session_id, content, ai_reply_full)
                    )
            
            yield {
                "event": "done",
                "data": {
                    "session_id": session_id
                }
            }
            
        except Exception as e:
            logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥ï¼ˆæµå¼ï¼‰: {e}", exc_info=True)
            yield {
                "event": "error",
                "data": {
                    "message": f"å‘é€å¤±è´¥: {str(e)}"
                }
            }
    
    async def get_session_messages(
        self,
        session_id: str,
        page: int = 1,
        page_size: int = 50
    ) -> Tuple[str, int, Optional[Dict[str, Any]]]:
        """
        è·å–ä¼šè¯çš„æ‰€æœ‰æ¶ˆæ¯
        
        Args:
            session_id: ä¼šè¯ID
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            
        Returns:
            (message, ret, data)
        """
        try:
            logger.info(f"è·å–ä¼šè¯æ¶ˆæ¯: session={session_id}, page={page}, page_size={page_size}")
            
            # æŸ¥è¯¢æ¶ˆæ¯
            query = MessageModel.find(MessageModel.session_id == session_id)
            
            # æ’åºï¼šæŒ‰åˆ›å»ºæ—¶é—´å‡åº
            query = query.sort(MessageModel.created_at)
            
            # åˆ†é¡µ
            skip = (page - 1) * page_size
            messages = await query.skip(skip).limit(page_size).to_list()
            
            # æ€»æ•°
            total = await MessageModel.find(MessageModel.session_id == session_id).count()
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            messages_data = []
            for msg in messages:
                messages_data.append({
                    "uuid": msg.uuid,
                    "session_id": msg.session_id,
                    "content": msg.content,
                    "send_type": msg.send_type,
                    "send_id": msg.send_id,
                    "send_name": msg.send_name,
                    "send_avatar": msg.send_avatar,
                    "receive_id": msg.receive_id,
                    "file_type": msg.file_type,
                    "file_name": msg.file_name,
                    "file_size": msg.file_size,
                    "status": msg.status,
                    "extra_data": msg.extra_data,  # ğŸ”¥ è¿”å›é¢å¤–æ•°æ®ï¼ˆæ€è€ƒè¿‡ç¨‹ã€æ–‡æ¡£ç­‰ï¼‰
                    "created_at": msg.created_at.isoformat() if msg.created_at else None,
                    "send_at": msg.send_at.isoformat() if msg.send_at else None
                })
            
            data = {
                "total": total,
                "messages": messages_data
            }
            
            logger.info(f"è·å–ä¼šè¯æ¶ˆæ¯æˆåŠŸ: session={session_id}, å…± {total} æ¡æ¶ˆæ¯")
            return "è·å–æˆåŠŸ", 0, data
            
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
            return f"è·å–å¤±è´¥: {str(e)}", -1, None


# åˆ›å»ºå•ä¾‹å®ä¾‹
message_service = MessageService()
