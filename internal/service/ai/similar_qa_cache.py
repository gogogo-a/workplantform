"""
ç›¸ä¼¼é—®ç­”ç¼“å­˜
è´Ÿè´£æ£€ç´¢ç›¸ä¼¼é—®é¢˜çš„å†å²å›ç­”ï¼Œé¿å…é‡å¤æ¨ç†
"""
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta

from log import logger
from internal.db.milvus import milvus_client
from internal.embedding.embedding_service import embedding_service
from internal.model.thought_chain import ThoughtChainModel
from pkg.constants.constants import (
    ENABLE_QA_CACHE,
    QA_SIMILARITY_THRESHOLD,
    QA_CACHE_TTL
)


class SimilarQACache:
    """
    ç›¸ä¼¼é—®ç­”ç¼“å­˜ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
    
    è´Ÿè´£ï¼š
    - æ£€ç´¢ç›¸ä¼¼é—®é¢˜çš„å†å²å›ç­”
    - é¿å…å¯¹ç›¸åŒ/ç›¸ä¼¼é—®é¢˜é‡å¤è°ƒç”¨ Agent
    - èŠ‚çœ Token å’Œå“åº”æ—¶é—´
    - æ”¯æŒæ—¶é—´è¿‡æ»¤å’Œå¤šç»“æœé€‰æ‹©
    """
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–ç›¸ä¼¼é—®ç­”ç¼“å­˜"""
        if not hasattr(self, '_initialized'):
            self._initialized = True
            self.similarity_threshold = QA_SIMILARITY_THRESHOLD
            self.cache_ttl = QA_CACHE_TTL  # ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆç§’ï¼‰
    
    def is_enabled(self) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜åŠŸèƒ½æ˜¯å¦å¯ç”¨
        
        Returns:
            æ˜¯å¦å¯ç”¨
        """
        return ENABLE_QA_CACHE
    
    async def find_similar(
        self,
        question: str,
        user_id: Optional[str] = None,
        skip_cache: bool = False
    ) -> Optional[Dict[str, Any]]:
        """
        æ£€ç´¢ç›¸ä¼¼é—®é¢˜çš„å†å²å›ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œç”¨äºä¸ªæ€§åŒ–æ£€ç´¢ï¼‰
            skip_cache: æ˜¯å¦è·³è¿‡ç¼“å­˜ï¼ˆé‡æ–°å›ç­”æ—¶ä½¿ç”¨ï¼‰
            
        Returns:
            å¦‚æœæ‰¾åˆ°ç›¸ä¼¼é—®é¢˜ï¼Œè¿”å›ï¼š
            {
                "question": åŸå§‹é—®é¢˜,
                "answer": å†å²ç­”æ¡ˆ,
                "thought_chain_id": æ€ç»´é“¾ID,
                "similarity": ç›¸ä¼¼åº¦åˆ†æ•°,
                "documents": å¼•ç”¨çš„æ–‡æ¡£
            }
            å¦åˆ™è¿”å› None
        """
        if not self.is_enabled() or skip_cache:
            return None
        
        try:
            # 1. ç”Ÿæˆé—®é¢˜çš„ embedding
            question_embedding = embedding_service.encode_query(question)
            
            # 2. åœ¨ Milvus ä¸­æ£€ç´¢ç›¸ä¼¼é—®é¢˜ï¼ˆè·å–å¤šä¸ªç»“æœç”¨äºç­›é€‰ï¼‰
            similar_results = milvus_client.search_similar_questions(
                query_embedding=question_embedding,
                top_k=5,  # è·å–å¤šä¸ªç»“æœ
                score_threshold=self.similarity_threshold
            )
            
            if not similar_results:
                return None
            
            # 3. ä»å¤šä¸ªç»“æœä¸­é€‰æ‹©æœ€ä½³çš„ï¼ˆè€ƒè™‘æ—¶é—´ã€ç‚¹èµæ•°ç­‰ï¼‰
            best_match = await self._select_best_match(similar_results)
            
            if not best_match:
                return None
            
            thought_chain_id = best_match.get("metadata", {}).get("thought_chain_id")
            
            if not thought_chain_id:
                logger.warning("ç›¸ä¼¼é—®é¢˜ç¼ºå°‘ thought_chain_id")
                return None
            
            # 4. ä» MongoDB è·å–å®Œæ•´çš„æ€ç»´é“¾å’Œç­”æ¡ˆ
            thought_chain = await ThoughtChainModel.find_one(
                ThoughtChainModel.uuid == thought_chain_id
            )
            
            if not thought_chain:
                logger.warning(f"æ€ç»´é“¾ä¸å­˜åœ¨: {thought_chain_id}")
                return None
            
            # 5. æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if self._is_expired(thought_chain.created_at):
                logger.debug(f"ç¼“å­˜å·²è¿‡æœŸ: {thought_chain_id}")
                return None
            
            logger.info(f"ğŸ¯ å‘½ä¸­ç›¸ä¼¼é—®é¢˜ç¼“å­˜: similarity={best_match['score']:.4f}, likes={thought_chain.like_count}")
            
            return {
                "question": best_match["text"],
                "answer": thought_chain.answer,
                "thought_chain_id": thought_chain_id,
                "thought_chain": thought_chain.thought_chain,
                "similarity": best_match["score"],
                "documents": thought_chain.documents_used,
                "like_count": thought_chain.like_count,
                "dislike_count": thought_chain.dislike_count
            }
            
        except Exception as e:
            logger.error(f"æ£€ç´¢ç›¸ä¼¼é—®é¢˜å¤±è´¥: {e}", exc_info=True)
            return None
    
    async def _select_best_match(self, results: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        ä»å¤šä¸ªç›¸ä¼¼ç»“æœä¸­é€‰æ‹©æœ€ä½³çš„
        
        é€‰æ‹©ç­–ç•¥ï¼š
        1. è¿‡æ»¤æ‰è¿‡æœŸçš„
        2. è¿‡æ»¤æ‰è¸©æ•°è¿‡å¤šçš„
        3. æŒ‰ (ç›¸ä¼¼åº¦ * 0.6 + ç‚¹èµæƒé‡ * 0.4) æ’åº
        
        Args:
            results: Milvus æœç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            æœ€ä½³åŒ¹é…ç»“æœ
        """
        if not results:
            return None
        
        valid_results = []
        
        for result in results:
            thought_chain_id = result.get("metadata", {}).get("thought_chain_id")
            if not thought_chain_id:
                continue
            
            # ä» MongoDB è·å–æ€ç»´é“¾ä¿¡æ¯
            thought_chain = await ThoughtChainModel.find_one(
                ThoughtChainModel.uuid == thought_chain_id
            )
            
            if not thought_chain:
                continue
            
            # è¿‡æ»¤è¿‡æœŸçš„
            if self._is_expired(thought_chain.created_at):
                continue
            
            # è¿‡æ»¤å‡€è¸©æ•°è¿‡å¤šçš„ï¼ˆè¸©æ•° - èµæ•° >= 3 åˆ™ä¸ä½¿ç”¨ï¼‰
            net_dislike = thought_chain.dislike_count - thought_chain.like_count
            if net_dislike >= 3:
                continue
            
            # è®¡ç®—ç»¼åˆå¾—åˆ†
            similarity_score = result["score"]
            like_weight = min(thought_chain.like_count * 0.05, 0.2)  # ç‚¹èµåŠ åˆ†ï¼Œæœ€å¤š 0.2
            dislike_penalty = thought_chain.dislike_count * 0.1  # è¸©å‡åˆ†
            
            combined_score = similarity_score * 0.6 + like_weight - dislike_penalty
            
            valid_results.append({
                **result,
                "combined_score": combined_score,
                "thought_chain": thought_chain
            })
        
        if not valid_results:
            return None
        
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        valid_results.sort(key=lambda x: x["combined_score"], reverse=True)
        
        return valid_results[0]
    
    def _is_expired(self, created_at: datetime) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        
        Args:
            created_at: åˆ›å»ºæ—¶é—´
            
        Returns:
            æ˜¯å¦è¿‡æœŸ
        """
        if self.cache_ttl <= 0:
            return False  # TTL <= 0 è¡¨ç¤ºæ°¸ä¸è¿‡æœŸ
        
        expiry_time = created_at + timedelta(seconds=self.cache_ttl)
        return datetime.now() > expiry_time
    
    async def delete_cache(self, thought_chain_id: str) -> bool:
        """
        åˆ é™¤æŒ‡å®šçš„ QA ç¼“å­˜
        
        Args:
            thought_chain_id: æ€ç»´é“¾ UUID
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            # 1. ä» Milvus åˆ é™¤
            milvus_client.delete_qa_cache_by_thought_chain_id(thought_chain_id)
            
            # 2. æ›´æ–° MongoDB ä¸­çš„ç¼“å­˜çŠ¶æ€
            thought_chain = await ThoughtChainModel.find_one(
                ThoughtChainModel.uuid == thought_chain_id
            )
            if thought_chain:
                thought_chain.is_cached = False
                thought_chain.milvus_id = None
                await thought_chain.save()
            
            logger.info(f"âœ“ å·²åˆ é™¤ QA ç¼“å­˜: {thought_chain_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤ QA ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
            return False
    
    async def update_feedback(
        self,
        thought_chain_id: str,
        feedback_type: str,  # "like" æˆ– "dislike"
        user_id: str = None  # ç”¨æˆ·IDï¼Œç”¨äºé˜²æ­¢é‡å¤æ“ä½œ
    ) -> Dict[str, Any]:
        """
        æ›´æ–°åé¦ˆï¼ˆç‚¹èµ/è¸©ï¼‰
        
        Args:
            thought_chain_id: æ€ç»´é“¾ UUID
            feedback_type: åé¦ˆç±»å‹ ("like" æˆ– "dislike")
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºé˜²æ­¢é‡å¤æ“ä½œï¼‰
            
        Returns:
            æ›´æ–°åçš„ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            thought_chain = await ThoughtChainModel.find_one(
                ThoughtChainModel.uuid == thought_chain_id
            )
            
            if not thought_chain:
                return {"success": False, "message": "æ€ç»´é“¾ä¸å­˜åœ¨"}
            
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²ç»åé¦ˆè¿‡
            if user_id:
                previous_feedback = thought_chain.user_feedbacks.get(user_id)
                
                if previous_feedback == feedback_type:
                    # ç›¸åŒæ“ä½œï¼Œä¸å…è®¸é‡å¤
                    return {
                        "success": False, 
                        "message": "æ‚¨å·²ç»æäº¤è¿‡ç›¸åŒçš„åé¦ˆ",
                        "like_count": thought_chain.like_count,
                        "dislike_count": thought_chain.dislike_count,
                        "is_cached": thought_chain.is_cached
                    }
                
                if previous_feedback:
                    # åˆ‡æ¢åé¦ˆï¼šå…ˆæ’¤é”€ä¹‹å‰çš„
                    if previous_feedback == "like":
                        thought_chain.like_count = max(0, thought_chain.like_count - 1)
                    elif previous_feedback == "dislike":
                        thought_chain.dislike_count = max(0, thought_chain.dislike_count - 1)
            
            # æ›´æ–°æ–°çš„åé¦ˆ
            if feedback_type == "like":
                thought_chain.like_count += 1
            elif feedback_type == "dislike":
                thought_chain.dislike_count += 1
            
            # è®°å½•ç¼“å­˜åˆ é™¤çŠ¶æ€
            was_cached = thought_chain.is_cached
            cache_deleted = False
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ é™¤ç¼“å­˜ï¼šè¸©æ•° - èµæ•° >= 3 æ—¶è‡ªåŠ¨åˆ é™¤
            net_dislike = thought_chain.dislike_count - thought_chain.like_count
            if net_dislike >= 3 and thought_chain.is_cached:
                await self.delete_cache(thought_chain_id)
                cache_deleted = True
                logger.info(f"âš ï¸ å‡€è¸©æ•°è¾¾åˆ°é˜ˆå€¼({net_dislike})ï¼Œå·²è‡ªåŠ¨åˆ é™¤ç¼“å­˜: {thought_chain_id}")
            
            # è®°å½•ç”¨æˆ·åé¦ˆ
            if user_id:
                thought_chain.user_feedbacks[user_id] = feedback_type
            
            await thought_chain.save()
            
            return {
                "success": True,
                "like_count": thought_chain.like_count,
                "dislike_count": thought_chain.dislike_count,
                "is_cached": thought_chain.is_cached,
                "was_cached": was_cached,  # æ“ä½œå‰æ˜¯å¦å·²ç¼“å­˜
                "cache_deleted": cache_deleted  # æœ¬æ¬¡æ“ä½œæ˜¯å¦åˆ é™¤äº†ç¼“å­˜
            }
            
        except Exception as e:
            logger.error(f"æ›´æ–°åé¦ˆå¤±è´¥: {e}", exc_info=True)
            return {"success": False, "message": str(e)}
    
    async def find_similar_batch(
        self,
        questions: List[str],
        user_id: Optional[str] = None
    ) -> List[Optional[Dict[str, Any]]]:
        """
        æ‰¹é‡æ£€ç´¢ç›¸ä¼¼é—®é¢˜
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            user_id: ç”¨æˆ·ID
            
        Returns:
            ç›¸ä¼¼é—®é¢˜ç»“æœåˆ—è¡¨ï¼ˆä¸è¾“å…¥é¡ºåºå¯¹åº”ï¼‰
        """
        results = []
        for question in questions:
            result = await self.find_similar(question, user_id)
            results.append(result)
        return results


# åˆ›å»ºå•ä¾‹å®ä¾‹
similar_qa_cache = SimilarQACache()
